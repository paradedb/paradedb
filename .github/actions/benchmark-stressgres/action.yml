name: Benchmark - Stressgres
description: Run a given Stressgres job file against pg_search and publish metrics

inputs:
  test_file:
    description: "The .toml Stressgres scenario to run (e.g. single-server.toml)"
    required: true
  duration:
    description: "Duration of the Stressgres run, in milliseconds"
    required: false
    default: "600000" # 10 minutes in milliseconds
  ref:
    description: "Git ref or short SHA to report in benchmarks"
    required: true
  github_token:
    description: "GitHub token to authenticate with"
    required: true
  slack_oauth_token:
    description: "Slack OAuth token to authenticate with"
    required: true
  slack_channel:
    description: "Slack channel to post results to"
    required: true
  slack_webhook_url:
    description: "Slack webhook URL to post results to"
    required: true
  pr_label:
    description: "The human readable version of the commit being tested"
    required: true

runs:
  using: "composite"
  steps:
    - name: Sanitize Inputs Into Variables
      id: sanitize-inputs
      shell: bash
      run: |
        # Strip .toml from the test file name
        echo "jobname=$(basename ${{ inputs.test_file }} .toml)" >> $GITHUB_OUTPUT

        # Strip slashes from the ref
        ref="${{ inputs.ref }}"
        safe_ref="${ref//\//-}"
        echo "safe_ref=$safe_ref" >> $GITHUB_OUTPUT

    - name: Run Stressgres Job
      shell: bash
      run: |
        sudo chmod a+rwx /var/run/postgresql/
        stressgres headless \
          .github/stressgres/${{ inputs.test_file }} \
          --log-file stressgres-${{ steps.sanitize-inputs.outputs.jobname }}.log \
          --runtime ${{ inputs.duration }}

    - name: Generate CSV
      shell: bash
      run: stressgres csv stressgres-${{ steps.sanitize-inputs.outputs.jobname }}.log output.csv

      # This is where we can configure how the different runs are aggregated
      # into multiple JSON files for plotting in our continuous benchmarks.
      #
      # TPS values are pulled out separately as they're "bigger-is-better" whereas
      # everything else is "smaller-is-better"
    - name: Generate Continuous Benchmarking Metrics
      shell: python {0}
      run: |
        import csv, json, os
        tps, other = [], []
        with open(f"output.csv") as f:
            reader = csv.DictReader(f)
            for row in reader:
                m = {
                  "name": f"{row['job_title']} - {row['server_name']} - {row['metric_name']}",
                  "unit": f"median {row['metric_name']}",
                  "value": float(row['median']),
                  "extra": f"avg {row['metric_name']}: {row['avg']}, max {row['metric_name']}: {row['max']}, count: {row['count']}"
                }
                if row["metric_name"] == "tps":
                    tps.append(m)
                else:
                    other.append(m)
        tps.sort(key=lambda x: x["name"])
        other.sort(key=lambda x: x["name"])
        with open(f"pg_search_tps.json", "w")  as o: json.dump(tps, o)
        with open(f"pg_search_other.json", "w") as o: json.dump(other, o)

    # Necessary to avoid "destination path is not empty" error
    - name: Cleanup Previous Benchmark Publish Working Directory
      shell: bash
      run: rm -rf ./benchmark-data-repository

    # we sleep for a random number of seconds to hopefully avoid conflicting with other concurrent
    # benchmark-action publish actions running in other jobs
    - name: Sleep before publish
      shell: bash
      run: echo $(( 1 + RANDOM % ( 61 - 1 + 1 ) ))

    - name: Publish TPS Metrics
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: "pg_search ${{ inputs.test_file }} Performance - TPS"
        ref: ${{ inputs.ref }}
        tool: customBiggerIsBetter
        output-file-path: pg_search_tps.json
        github-token: ${{ inputs.github_token }}
        gh-repository: github.com/paradedb/paradedb
        gh-pages-branch: gh-pages
        auto-push: ${{ github.event_name != 'pull_request' }}
        benchmark-data-dir-path: stressgres
        alert-threshold: "110%"
        comment-on-alert: true # We comment and alert rather than failing, as we have both Github and Slack messages to notify us
        alert-comment-cc-users: "@${{ github.actor }}"
        comment-always: ${{ github.event_name == 'pull_request' }}

    # Necessary to avoid "destination path is not empty" error
    - name: Cleanup Previous Benchmark Publish Working Directory
      shell: bash
      run: rm -rf ./benchmark-data-repository

    # we sleep for a random number of seconds to hopefully avoid conflicting with other concurrent
    # benchmark-action publish actions running in other jobs
    - name: Sleep before publish
      shell: bash
      run: echo $(( 1 + RANDOM % ( 61 - 1 + 1 ) ))

    - name: Publish Other Metrics
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: "pg_search ${{ inputs.test_file }} Performance - Other Metrics"
        ref: ${{ inputs.ref }}
        tool: customSmallerIsBetter
        output-file-path: pg_search_other.json
        github-token: ${{ inputs.github_token }}
        gh-repository: github.com/paradedb/paradedb
        gh-pages-branch: gh-pages
        auto-push: ${{ github.event_name != 'pull_request' }}
        benchmark-data-dir-path: stressgres
        alert-threshold: "110%"
        comment-on-alert: true
        alert-comment-cc-users: "@${{ github.actor }}"
        comment-always: ${{ github.event_name == 'pull_request' }}

    - name: Create Stressgres Graph
      shell: bash
      run: stressgres graph "stressgres-${{ steps.sanitize-inputs.outputs.jobname }}.log" "stressgres-${{ steps.sanitize-inputs.outputs.jobname }}-${{ github.sha }}.png"

    - name: Upload Stressgres Results to Slack (push only)
      if: github.event_name != 'pull_request'
      uses: slackapi/slack-github-action@v2
      with:
        method: files.uploadV2
        token: ${{ inputs.slack_oauth_token }}
        payload: |
          channel_id: ${{ inputs.slack_channel }}
          initial_comment: |
            ${{ github.repository }} Stressgres Results: `${{ inputs.test_file }}`
            ${{ inputs.pr_label }} @ <${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}>
            <https://paradedb.github.io/paradedb/stressgres/>
          file: stressgres-${{ steps.sanitize-inputs.outputs.jobname }}-${{ github.sha }}.png
          filename: stressgres-${{ steps.sanitize-inputs.outputs.jobname }}-${{ github.sha }}.png

    - name: Print Postgres Logs
      shell: bash
      run: |
        for f in `ls /tmp/stressgres/*.log`; do
          echo $f
          cat $f
        done

    - name: Notify Slack on Failure (push only)
      if: failure() && github.event_name == 'push'
      shell: bash
      run: |
        GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        ARTIFACT_URL="${{ steps.artifact-logs.outputs.artifact-url }}"
        MESSAGE="<!here> \`benchmark-pg_search-stressgres\` workflow (${{ inputs.test_file }}) failed in \`paradedb/paradedb\` -- investigate immediately! GitHub Action Logs: ${GITHUB_RUN_URL} | Stressgres Log: ${ARTIFACT_URL}"
        curl -X POST -H 'Content-type: application/json' -d "{\"text\": \"${MESSAGE}\"}" ${{ inputs.slack_webhook_url }}
