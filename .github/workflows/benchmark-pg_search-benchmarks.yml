# workflows/benchmark-pg_search-benchmarks.yml
#
# Benchmark pg_search - Benchmarks
# Run our benchmarks suite against pg_search.

name: Benchmark pg_search - Benchmarks

# We run benchmarks on `main`, and on `benchmark`-labeled PRs.
on:
  push:
    branches:
      - main
      - 0.*.x # Release branches
      - phil/nvme-test
    paths:
      - "benchmarks/**"
      - "**/*.rs"
      - "**/*.toml"
  pull_request:
    types: [labeled, synchronize]
    branches:
      - main
      - 0.*.x # Release branches
  workflow_dispatch:
    inputs:
      commit:
        description: "A specific commit hash or tag to benchmark. Uses `main` if not specified."
        required: false
        default: ""

permissions:
  actions: write
  contents: write
  deployments: write
  pull-requests: write

# We don't specify a concurrency group here, as we want all jobs to complete.

jobs:
  benchmark-pg_search-benchmarks:
    name: Run Benchmark Jobs
    runs-on:
      # To configure the runners: https://runs-on.com/configuration/job-labels/#how-it-works (runs in us-east-1)
      - runs-on=${{ github.run_id }}
      - family=z1d.metal # 48 vCPUs, 384 GiBs Memory, 1.8 TiBs local NVMe
      - image=ubuntu24-full-x64
      - extras=s3-cache # See https://runs-on.com/caching/magic-cache/
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || (github.event_name == 'pull_request' && github.event.label.name == 'benchmark') || (github.event_name == 'pull_request' && github.event.label.name == 'benchmark-benchmarks')
    env:
      pg_version: 17

    steps:
      # The job can be triggered manually by attaching the `benchmark` label to a PR. This step
      # removes the label once the job has started, so it can be applied again if needed.
      - name: Maybe Remove Label
        uses: actions-ecosystem/action-remove-labels@v1
        if: github.event_name == 'pull_request' && github.event.label.name == 'benchmark' || github.event_name == 'pull_request' && github.event.label.name == 'benchmark-benchmarks'
        with:
          labels: |
            benchmark
            benchmark-benchmarks

      - name: BEFORE | Detect actual backing device (handles overlayfs → upperdir)
        shell: bash
        run: |
          set -euo pipefail
          TARGET_DIR="${GITHUB_WORKSPACE:-/home/runner/_work}"

          echo "Target: $TARGET_DIR"

          # If overlay, extract upperdir; else just use TARGET_DIR
          readarray -t info < <(findmnt -T "$TARGET_DIR" -no SOURCE,FSTYPE,OPTIONS)
          src=$(awk '{print $1}' <<<"${info[0]}")
          fstype=$(awk '{print $2}' <<<"${info[0]}")
          opts=$(awk '{print $3}' <<<"${info[0]}")

          probe_path="$TARGET_DIR"
          if [[ "$fstype" == "overlay" ]]; then
            upperdir=$(sed -n 's/.*upperdir=\([^,]*\).*/\1/p' <<<"$opts" | head -n1)
            workdir=$(sed -n 's/.*workdir=\([^,]*\).*/\1/p' <<<"$opts" | head -n1)
            echo "overlayfs detected."
            echo "  upperdir: $upperdir"
            echo "  workdir:  $workdir"
            probe_path="${upperdir:-$TARGET_DIR}"
          fi

          echo "Probing underlying FS for: $probe_path"
          dev=$(df -P "$probe_path" | tail -1 | awk '{print $1}')
          real=$(readlink -f "$dev" || echo "$dev")
          # resolve mapper/root indirections → parent block device
          base=$(basename "$real")
          parent=$(lsblk -no PKNAME "$real" 2>/dev/null || true)
          [[ -n "$parent" ]] && base="$parent"

          model="UNKNOWN"; vendor="UNKNOWN"
          [[ -r "/sys/block/$base/device/model"  ]] && model=$(<"/sys/block/$base/device/model")
          [[ -r "/sys/block/$base/device/vendor" ]] && vendor=$(<"/sys/block/$base/device/vendor")

          echo "Mount source: $src"
          echo "FSType:       $fstype"
          echo "df device:    $dev (real: $real, base: /dev/$base)"
          echo "Vendor:       $vendor"
          echo "Model:        $model"

          case "$model" in
            *"EC2 NVMe Instance Storage"*)
              echo "Verdict: LOCAL NVMe (instance-store)";;
            *"Elastic Block Store"*)
              echo "Verdict: EBS (NVMe-backed)";;
            *)
              echo "Verdict: UNKNOWN";;
          esac

          echo
          echo "Available NVMe devices:"
          if ! command -v nvme >/dev/null; then
            sudo apt-get update -y && sudo apt-get install -y nvme-cli
          fi
          nvme list || true

      - name: Mount local NVMe and move workspace to it (safe, idempotent)
        shell: bash
        run: |
          set -euo pipefail

          # Pick the first *instance-store* NVMe that is not mounted
          cand=$(nvme list | awk '/EC2 NVMe Instance Storage/{print $1}' | head -n1)
          if [[ -z "$cand" ]]; then
            echo "No EC2 NVMe Instance Storage device found."; exit 0
          fi
          dev="$cand"
          part="${dev}p1"

          # Partition if needed
          if ! lsblk -no TYPE "$part" >/dev/null 2>&1; then
            echo -e "g\nn\n1\n\n\nw" | sudo fdisk "$dev"
            sudo partprobe "$dev"
          fi

          # Make filesystem if missing (XFS preferred for large-file workloads)
          fstype=$(lsblk -no FSTYPE "$part")
          if [[ -z "${fstype:-}" ]]; then
            sudo mkfs.xfs -f "$part" || sudo mkfs.ext4 -F "$part"
          fi

          # Mount it
          sudo mkdir -p /mnt/nvme
          if ! mountpoint -q /mnt/nvme; then
            sudo mount "$part" /mnt/nvme
          fi
          sudo chown -R "$USER:$USER" /mnt/nvme

          # Move the *runner workspace root* (one level above your repo) onto NVMe
          runner_root="/home/runner/_work"
          mkdir -p /mnt/nvme/_work

          # If not already bind-mounted, populate once and bind
          if ! mountpoint -q "$runner_root"; then
            rsync -aHAX --delete "$runner_root"/ /mnt/nvme/_work/
            sudo mount --bind /mnt/nvme/_work "$runner_root"
            echo "Bound $runner_root to NVMe."
          else
            echo "$runner_root is already a mountpoint; skipping bind."
          fi

          # Speed up temp files too
          sudo rm -rf /tmp && sudo mkdir -p /mnt/nvme/tmp && sudo ln -s /mnt/nvme/tmp /tmp

          df -hT "$runner_root" /tmp

      - name: AFTER | Detect actual backing device (handles overlayfs → upperdir)
        shell: bash
        run: |
          set -euo pipefail
          TARGET_DIR="${GITHUB_WORKSPACE:-/home/runner/_work}"

          echo "Target: $TARGET_DIR"

          # If overlay, extract upperdir; else just use TARGET_DIR
          readarray -t info < <(findmnt -T "$TARGET_DIR" -no SOURCE,FSTYPE,OPTIONS)
          src=$(awk '{print $1}' <<<"${info[0]}")
          fstype=$(awk '{print $2}' <<<"${info[0]}")
          opts=$(awk '{print $3}' <<<"${info[0]}")

          probe_path="$TARGET_DIR"
          if [[ "$fstype" == "overlay" ]]; then
            upperdir=$(sed -n 's/.*upperdir=\([^,]*\).*/\1/p' <<<"$opts" | head -n1)
            workdir=$(sed -n 's/.*workdir=\([^,]*\).*/\1/p' <<<"$opts" | head -n1)
            echo "overlayfs detected."
            echo "  upperdir: $upperdir"
            echo "  workdir:  $workdir"
            probe_path="${upperdir:-$TARGET_DIR}"
          fi

          echo "Probing underlying FS for: $probe_path"
          dev=$(df -P "$probe_path" | tail -1 | awk '{print $1}')
          real=$(readlink -f "$dev" || echo "$dev")
          # resolve mapper/root indirections → parent block device
          base=$(basename "$real")
          parent=$(lsblk -no PKNAME "$real" 2>/dev/null || true)
          [[ -n "$parent" ]] && base="$parent"

          model="UNKNOWN"; vendor="UNKNOWN"
          [[ -r "/sys/block/$base/device/model"  ]] && model=$(<"/sys/block/$base/device/model")
          [[ -r "/sys/block/$base/device/vendor" ]] && vendor=$(<"/sys/block/$base/device/vendor")

          echo "Mount source: $src"
          echo "FSType:       $fstype"
          echo "df device:    $dev (real: $real, base: /dev/$base)"
          echo "Vendor:       $vendor"
          echo "Model:        $model"

          case "$model" in
            *"EC2 NVMe Instance Storage"*)
              echo "Verdict: LOCAL NVMe (instance-store)";;
            *"Elastic Block Store"*)
              echo "Verdict: EBS (NVMe-backed)";;
            *)
              echo "Verdict: UNKNOWN";;
          esac

          echo
          echo "Available NVMe devices:"
          if ! command -v nvme >/dev/null; then
            sudo apt-get update -y && sudo apt-get install -y nvme-cli
          fi
          nvme list || true

      # - name: Determine Ref to Benchmark
      #   id: determine-ref
      #   run: |
      #     # Use a workflow-provided commit (if any), else a PR's head ref, else the main branch.
      #     REF=${{ inputs.commit || (github.event_name == 'pull_request' && github.head_ref) || 'main' }}
      #     echo "ref=$REF" >> $GITHUB_OUTPUT

      # - name: Derive Short Commit
      #   id: commit_info
      #   run: |
      #     short_commit=$(echo "${GITHUB_SHA}" | cut -c1-7)
      #     echo "short_commit=$short_commit" >> $GITHUB_OUTPUT

      # - name: Checkout Git Repository at ref=${{ steps.determine-ref.outputs.ref }}
      #   uses: actions/checkout@v4
      #   with:
      #     ref: ${{ steps.determine-ref.outputs.ref }}

      # - name: Fetch the Latest Composite Actions
      #   if: github.event.label.name != 'benchmark' && github.event.label.name != 'benchmark-benchmarks'
      #   uses: actions/checkout@v4
      #   with:
      #     repository: ${{ github.repository }}
      #     path: actions-temp
      #     token: ${{ secrets.GITHUB_TOKEN }}
      #     fetch-depth: 1
      #     ref: main

      # - name: Copy latest actions into place
      #   if: github.event.label.name != 'benchmark' && github.event.label.name != 'benchmark-benchmarks'
      #   run: cp -rv actions-temp/.github/actions .github/

      # - name: Cleanup temporary checkout
      #   if: github.event.label.name != 'benchmark' && github.event.label.name != 'benchmark-benchmarks'
      #   run: rm -rf actions-temp

      # # only fetch the latest from main when, essentially, we're merging to main.  otherwise, use whatever we checked out in the ref we're benchmarking
      # - name: Fetch latest benchmark code, suites
      #   if: github.event.label.name != 'benchmark' && github.event.label.name != 'benchmark-benchmarks'
      #   uses: ./.github/actions/benchmarks-from-main
      #   with:
      #     github-token: ${{ secrets.GITHUB_TOKEN }}

      # - name: Resolve git ref to PR
      #   id: pr_label
      #   uses: actions/github-script@v7
      #   env:
      #     # ← Set this to whatever ref you’re resolving:
      #     # • a SHA:            ${{ github.sha }}
      #     # • a branch name:    ${{ github.ref_name }}
      #     # • a tag:            ${{ github.ref_name }}
      #     # • a PR number:      e.g. “123”
      #     TARGET_REF: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
      #   with:
      #     github-token: ${{ secrets.GITHUB_TOKEN }}
      #     result-encoding: string
      #     script: |
      #       const { owner, repo } = context.repo;
      #       const ref = process.env.TARGET_REF;

      #       let pr = null;

      #       // If the ref is purely numeric, treat it as a PR number
      #       if (/^\d+$/.test(ref)) {
      #         try {
      #           const { data } = await github.rest.pulls.get({
      #             owner,
      #             repo,
      #             pull_number: parseInt(ref, 10)
      #           });
      #           pr = data;
      #         } catch (e) {
      #           // not a valid PR number → fall through
      #         }
      #       }

      #       // Otherwise, try to find any PR associated with this commit SHA
      #       if (!pr) {
      #         const res = await github.request(
      #           'GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls',
      #           {
      #             owner,
      #             repo,
      #             commit_sha: ref,
      #             headers: {
      #               accept: 'application/vnd.github.groot-preview+json'
      #             }
      #           }
      #         );
      #         if (res.data.length) {
      #           pr = res.data[0];
      #         }
      #       }

      #       // Return “PR #123: Title” or the raw ref
      #       return pr
      #         ? `PR #${pr.number}: ${pr.title}`
      #         : ref;

      # - name: Running for ${{ steps.pr_label.outputs.result }}"
      #   run: echo ${{ steps.pr_label.outputs.result }}

      # - name: Install Rust
      #   uses: actions-rust-lang/setup-rust-toolchain@v1

      # - name: Install & Configure Supported PostgreSQL Version
      #   run: |
      #     wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
      #     sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
      #     sudo apt-get update && sudo apt-get install -y postgresql-${{ env.pg_version }} postgresql-server-dev-${{ env.pg_version }}
      #     echo "/usr/lib/postgresql/${{ env.pg_version }}/bin" >> $GITHUB_PATH

      # - name: Install Rust Cache
      #   uses: swatinem/rust-cache@v2
      #   with:
      #     prefix-key: "v1-benchmarks-rust-cache"
      #     shared-key: pg${{ env.pg_version }}-${{ hashFiles('**/Cargo.lock') }}
      #     cache-targets: true
      #     cache-all-crates: true
      #     cache-on-failure: true

      # - name: Extract pgrx Version
      #   id: pgrx
      #   working-directory: pg_search/
      #   run: |
      #     version=$(cargo tree --depth 1 -i pgrx -p pg_search | head -n 1 | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/\1/')
      #     echo "version=$version" >> $GITHUB_OUTPUT

      # - name: Install cargo-pgrx
      #   run: cargo install cargo-pgrx --version ${{ steps.pgrx.outputs.version }} --debug --locked

      # - name: Initialize cargo-pgrx environment
      #   run: cargo pgrx init --pg${{ env.pg_version }}=`which pg_config`

      # - name: Compile & install pg_search extension
      #   run: cargo pgrx install -p pg_search --sudo --release --pg-config `which pg_config` --features=pg${{ env.pg_version }},icu --no-default-features

      # - name: Configure PostgreSQL settings
      #   working-directory: /home/runner/.pgrx/data-${{ env.pg_version }}/
      #   run: |
      #     sed -i "s/^#shared_preload_libraries = .*/shared_preload_libraries = 'pg_search'/" postgresql.conf
      #     sed -i "s/^#maintenance_work_mem = .*/maintenance_work_mem = '12GB'/" postgresql.conf
      #     sed -i "s/^shared_buffers = .*/shared_buffers = '12GB'/" postgresql.conf
      #     sed -i "s/^#max_parallel_workers = .*/max_parallel_workers = 8/" postgresql.conf
      #     sed -i "s/^#max_worker_processes = .*/max_worker_processes = 8/" postgresql.conf
      #     sed -i "s/^#max_parallel_maintenance_workers = .*/max_parallel_maintenance_workers = 8/" postgresql.conf
      #     sed -i "s/^#max_parallel_workers_per_gather = .*/max_parallel_workers_per_gather = 8/" postgresql.conf

      # - name: Restart Postgres
      #   working-directory: pg_search/
      #   run: |
      #     cargo pgrx stop pg${{ env.pg_version }}
      #     cargo pgrx start pg${{ env.pg_version }}

      # - name: Install pg_search
      #   working-directory: pg_search/
      #   run: psql postgresql://localhost:288${{ env.pg_version }}/postgres -c "CREATE EXTENSION IF NOT EXISTS pg_search;"

      # - name: Benchmark "logs" Dataset
      #   uses: ./.github/actions/benchmark-benchmarks
      #   with:
      #     dataset: logs
      #     ref: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
      #     github_token: ${{ secrets.GITHUB_TOKEN }}
      #     slack_oauth_token: ${{ secrets.SLACK_OAUTH_TOKEN }}
      #     slack_channel: ${{ secrets.SLACK_BENCHMARKS_CHANNEL_ID }}
      #     pr_label: ${{ steps.pr_label.outputs.result }}

      # - name: Benchmark "docs" Dataset
      #   uses: ./.github/actions/benchmark-benchmarks
      #   with:
      #     dataset: docs
      #     ref: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
      #     github_token: ${{ secrets.GITHUB_TOKEN }}
      #     slack_oauth_token: ${{ secrets.SLACK_OAUTH_TOKEN }}
      #     slack_channel: ${{ secrets.SLACK_BENCHMARKS_CHANNEL_ID }}
      #     pr_label: ${{ steps.pr_label.outputs.result }}

      # - name: Notify Slack on Failure (push only)
      #   if: failure() && github.event_name == 'push'
      #   run: |
      #     GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
      #     MESSAGE="<!here> `benchmark-pg_search-benchmarks` workflow failed in `${{ github.repository }}` -- investigate immediately! GitHub Action Logs: ${GITHUB_RUN_URL}"
      #     curl -X POST -H 'Content-type: application/json' -d "{\"text\": \"${MESSAGE}\"}" ${{ secrets.SLACK_BENCHMARKS_CHANNEL_WEBHOOK_URL }}
