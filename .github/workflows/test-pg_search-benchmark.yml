# workflows/test-pg_search-benchmark.yml
#
# Test pg_search Benchmark
# Benchmark pg_search performance on a nightly basis. This workflow can also be triggered
# manually to benchmark other systems on one-off basis, to compare against pg_search.

name: Test pg_search Benchmark

# We run benchmarks on `main`, and on `benchmark`-labeled PRs.
on:
  push:
    branches:
      - main
    paths:
      - "benchmarks/**"
      - ".github/workflows/test-pg_search-benchmark.yml"
      - "**/*.rs"
      - "**/*.toml"
  pull_request:
    types: [labeled, synchronize]
    branches:
      - main
  workflow_dispatch:
    inputs:
      commit:
        description: "A specific commit hash or tag to benchmark.  Uses `main` if not specified."
        required: false
        default: ""

permissions:
  contents: write
  deployments: write
  pull-requests: write

#concurrency:
#  # If this is a manual backfill run, use the commit SHA.
#  # Otherwise (push/PR) fall back to the branch name.
#  group: ${{ format('query-benchmarks-{0}',
#    (github.event_name == 'workflow_dispatch' && inputs.commit) || github.ref) }}
#  # Keep auto-cancellation for normal CI, switch it off for backfills.
#  cancel-in-progress: ${{ github.event_name != 'workflow_dispatch' }}

jobs:
  benchmark-pg_search:
    name: Benchmark ${{ matrix.dataset }} on pg_search
    runs-on: depot-ubuntu-24.04-32
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch' || (github.event_name == 'pull_request' && github.event.label.name == 'benchmark')
    strategy:
      matrix:
        dataset: ["single", "join"]
    env:
      pg_version: 17

    steps:
      - name: Maybe remove label
        uses: actions-ecosystem/action-remove-labels@v1
        if: github.event_name == 'pull_request' && github.event.label.name == 'benchmark'
        with:
          labels: benchmark

      - name: Determine ref to benchmark
        id: determine-ref
        run: |
          # Use a workflow-provided commit (if any), else a PR's head ref, else the main branch.
          REF=${{ inputs.commit || (github.event_name == 'pull_request' && github.head_ref) || 'main' }}
          echo "::set-output name=ref::$REF"

      - name: Checkout Git Repository at ref=${{ steps.determine-ref.outputs.ref }}
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.determine-ref.outputs.ref }}

      # We manually fetch the benchmark queries from `main` to make sure all are available when backfilling
      # old commits potentially created before new queries were added.
      - name: Fetch the Latest Benchmark Queries
        run: |
          ls -la
          git clone --depth 1 --branch main https://github.com/paradedb/paradedb.git paradedb-temp
          cp -rv paradedb-temp/benchmarks .
          rm -rf paradedb-temp

          echo "Copied benchmark files:"
          ls -la benchmarks/

      - name: Install Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install & Configure Supported PostgreSQL Version
        run: |
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          sudo apt-get update && sudo apt-get install -y postgresql-${{ env.pg_version }} postgresql-server-dev-${{ env.pg_version }}
          echo "/usr/lib/postgresql/${{ env.pg_version }}/bin" >> $GITHUB_PATH

      - name: Extract pgrx Version
        id: pgrx
        working-directory: pg_search/
        run: |
          version=$(cargo tree --depth 1 -i pgrx -p pg_search | head -n 1 | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/\1/')
          echo "version=$version" >> $GITHUB_OUTPUT

      # Caches from base branches are available to PRs, but not across unrelated branches,
      # so we only save the cache on the default branch, but load it on all branches.
      - name: Install Rust Cache
        uses: swatinem/rust-cache@v2
        with:
          prefix-key: "v1-rust"
          key: ${{ env.pg_version }}-${{ steps.pgrx.outputs.version }}
          cache-targets: true
          cache-all-crates: true
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - name: Install pgrx & pg_search
        working-directory: pg_search/
        run: |
          cargo install -j $(nproc) --locked cargo-pgrx --version ${{ steps.pgrx.outputs.version }} --debug
          cargo pgrx init --pg${{ env.pg_version }}=/usr/lib/postgresql/${{ env.pg_version }}/bin/pg_config
          cargo pgrx install --sudo --release --pg-config="/usr/lib/postgresql/${{ env.pg_version }}/bin/pg_config"

      - name: Configure PostgreSQL settings
        working-directory: /home/runner/.pgrx/data-${{ env.pg_version }}/
        run: |
          sed -i "s/^#shared_preload_libraries = .*/shared_preload_libraries = 'pg_search'/" postgresql.conf
          sed -i "s/^#maintenance_work_mem = .*/maintenance_work_mem = '12GB'/" postgresql.conf
          sed -i "s/^shared_buffers = .*/shared_buffers = '12GB'/" postgresql.conf
          sed -i "s/^#max_parallel_workers = .*/max_parallel_workers = 8/" postgresql.conf
          sed -i "s/^#max_worker_processes = .*/max_worker_processes = 8/" postgresql.conf
          sed -i "s/^#max_parallel_maintenance_workers = .*/max_parallel_maintenance_workers = 8/" postgresql.conf
          sed -i "s/^#max_parallel_workers_per_gather = .*/max_parallel_workers_per_gather = 8/" postgresql.conf

      - name: Restart Postgres
        working-directory: pg_search/
        run: |
          cargo pgrx stop pg${{ env.pg_version }}
          cargo pgrx start pg${{ env.pg_version }}

      - name: Install pg_search
        working-directory: pg_search/
        run: |
          psql postgresql://localhost:288${{ env.pg_version }}/postgres -c "CREATE EXTENSION IF NOT EXISTS pg_search;"

      - name: Run Benchmark
        working-directory: benchmarks/
        run: |
          if [ "${{ matrix.dataset }}" = "single" ]; then
            NUM_ROWS=100000000
          elif [ "${{ matrix.dataset }}" = "join" ]; then
            NUM_ROWS=25000000
          else
            echo "Unknown dataset!"
            exit 1
          fi
          cargo run -- --url postgresql://localhost:288${{ env.pg_version }}/postgres --rows ${NUM_ROWS} --type pg_search --dataset ${{ matrix.dataset }} --runs 10 --output json

      - name: Cleanup git checkout
        run: |
          git checkout .

      # we sleep for a random number of seconds to hopefully avoid conflicting with other concurrent
      # benchmark-action publish actions running in other jobs
      - name: Sleep
        run: |
          LOW=1
          HIGH=66
          sleep $(( $LOW + RANDOM % ( $HIGH - $LOW + 1 ) ))

      - name: Check and Publish Continuous Benchmarking Metrics
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: "pg_search '${{ matrix.dataset }}' Query Performance"
          ref: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
          tool: "customSmallerIsBetter"
          output-file-path: "benchmarks/results.json"
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.event_name != 'pull_request' }}
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: benchmarks
          alert-threshold: "110%"
          # NB: We comment and alert rather than failing, as we have both Github and Slack messages
          # to notify us.
          comment-on-alert: true
          alert-comment-cc-users: "@${{ github.actor }}"
          comment-always: ${{ github.event_name == 'pull_request' }}

      - name: Notify Slack on Failure
        if: failure() && github.event_name == 'push'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_GITHUB_CHANNEL_WEBHOOK_URL }}
        run: |
          GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          MESSAGE="<!here> \`test-pg_search-benchmark\` workflow failed in \`paradedb/paradedb\` -- investigate immediately! GitHub Action Logs: ${GITHUB_RUN_URL}"
          curl -X POST -H 'Content-type: application/json' \
          --data "{\"text\": \"${MESSAGE}\"}" \
          ${SLACK_WEBHOOK_URL}

      - name: Derive Short Commit
        id: commit_info
        run: |
          short_commit=$(echo "${GITHUB_SHA}" | cut -c1-7)
          echo "short_commit=$short_commit" >> $GITHUB_OUTPUT

      - name: Report Benchmark Results to Slack
        if: github.event_name != 'pull_request'
        uses: slackapi/slack-github-action@v2
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_OAUTH_TOKEN }}
          payload: |
            channel: ${{ secrets.SLACK_BENCHMARKS_CHANNEL_ID }}
            text: |
              *<${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}>*: Community "${{ matrix.dataset}}" Query Results available:
              <https://paradedb.github.io/paradedb/benchmarks/>
          errors: true
          retries: 5
