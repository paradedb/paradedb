# workflows/test-pg_search-benchmark.yml
#
# Test pg_search Benchmark
# Benchmark pg_search performance on a nightly basis. This workflow can also be triggered
# manually to benchmark other systems on one-off basis, to compare against pg_search.

name: Test pg_search Benchmark

on:
  push: # We run benchmarks post-merge rather than on PRs to speed up CI. Results are posted to Slack.
    branches:
      - main
      - phil/depot-runners
    paths:
      - "benchmarks/**"
      - ".github/workflows/test-pg_search-benchmark.yml"
      - "**/*.rs"
      - "**/*.toml"
  workflow_dispatch:
    inputs:
      commit:
        description: "A specific commit hash or tag to benchmark.  Uses `main` if not specified."
        required: false
        default: ""

permissions:
  contents: write
  deployments: write

concurrency:
  group: test-pg_search-benchmark-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

jobs:
  benchmark-pg_search:
    name: Benchmark ${{ matrix.dataset }} on pg_search
    runs-on: depot-ubuntu-24.04-8
    strategy:
      matrix:
        dataset: ["single", "join"]
      env:
        pg_version: 17

    steps:
      - name: Checkout Git Repository
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.commit || 'main' }} # If no commit is provided, use the main branch.

      # We manually fetch the benchmark queries from `main` to make sure all are available when backfilling
      # old commits potentially created before new queries were added.
      - name: Fetch the Latest Benchmark Queries
        run: |
          ls -la
          git clone --depth 1 --branch main https://github.com/paradedb/paradedb.git paradedb-temp
          cp -rv paradedb-temp/benchmarks/ benchmarks/
          rm -rf paradedb-temp

          echo "Copied benchmark files:"
          ls -la benchmarks/

      - name: Install Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install & Configure Supported PostgreSQL Version
        run: |
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          sudo apt-get update && sudo apt-get install -y postgresql-${{ matrix.pg_version }} postgresql-server-dev-${{ matrix.pg_version }}
          echo "/usr/lib/postgresql/${{ matrix.pg_version }}/bin" >> $GITHUB_PATH

      - name: Extract pgrx Version
        id: pgrx
        working-directory: pg_search/
        run: |
          version=$(cargo tree --depth 1 -i pgrx -p pg_search | head -n 1 | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/\1/')
          echo "version=$version" >> $GITHUB_OUTPUT

      # Caches from base branches are available to PRs, but not across unrelated branches,
      # so we only save the cache on the default branch, but load it on all branches.
      - name: Install Rust Cache
        uses: swatinem/rust-cache@v2
        with:
          prefix-key: "v1-rust"
          key: ${{ matrix.pg_version }}-${{ steps.pgrx.outputs.version }}
          cache-targets: true
          cache-all-crates: true
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - name: Install pgrx & pg_search
        working-directory: pg_search/
        run: |
          cargo install -j $(nproc) --locked cargo-pgrx --version ${{ steps.pgrx.outputs.version }} --debug
          cargo pgrx init --pg${{ matrix.pg_version }}=/usr/lib/postgresql/${{ matrix.pg_version }}/bin/pg_config
          cargo pgrx install --sudo --release --pg-config="/usr/lib/postgresql/${{ matrix.pg_version }}/bin/pg_config"

      - name: Configure PostgreSQL settings
        working-directory: /home/runner/.pgrx/data-${{ matrix.pg_version }}/
        run: |
          sed -i "s/^#shared_preload_libraries = .*/shared_preload_libraries = 'pg_search'/" postgresql.conf
          sed -i "s/^#maintenance_work_mem = .*/maintenance_work_mem = '12GB'/" postgresql.conf
          sed -i "s/^shared_buffers = .*/shared_buffers = '12GB'/" postgresql.conf
          sed -i "s/^#max_parallel_workers = .*/max_parallel_workers = 8/" postgresql.conf
          sed -i "s/^#max_worker_processes = .*/max_worker_processes = 8/" postgresql.conf
          sed -i "s/^#max_parallel_maintenance_workers = .*/max_parallel_maintenance_workers = 8/" postgresql.conf
          sed -i "s/^#max_parallel_workers_per_gather = .*/max_parallel_workers_per_gather = 8/" postgresql.conf

      - name: Restart Postgres
        working-directory: pg_search/
        run: |
          cargo pgrx stop pg${{ matrix.pg_version }}
          cargo pgrx start pg${{ matrix.pg_version }}

      - name: Install pg_search
        working-directory: pg_search/
        run: |
          psql postgresql://localhost:288${{ matrix.pg_version }}/postgres -c "CREATE EXTENSION IF NOT EXISTS pg_search;"

      - name: Run Benchmark
        working-directory: benchmarks/
        run: |
          if [ "${{ matrix.dataset }}" = "single" ]; then
            NUM_ROWS=100000000
          elif [ "${{ matrix.dataset }}" = "join" ]; then
            NUM_ROWS=25000000
          else
            echo "Unknown dataset!"
            exit 1
          fi
          cargo run -- --url postgresql://localhost:288${{ matrix.pg_version }}/postgres --rows ${NUM_ROWS} --type pg_search --dataset ${{ matrix.dataset }} --runs 10 --output json

      - name: Check and Publish Continuous Benchmarking Metrics
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: "pg_search '${{ matrix.dataset }}' Query Performance"
          tool: "customSmallerIsBetter"
          output-file-path: "benchmarks/results.json"
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: benchmarks
          alert-threshold: "110%"
          # NB: We comment and alert rather than failing, as we have both Github and Slack messages
          # to notify us.
          comment-on-alert: true
          alert-comment-cc-users: "@${{ github.actor }}"

      - name: Notify Slack on Failure
        if: failure()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_GITHUB_CHANNEL_WEBHOOK_URL }}
        run: |
          GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          MESSAGE="<!here> \`test-pg_search-benchmark\` workflow failed in \`paradedb/paradedb\` -- investigate immediately! GitHub Action Logs: ${GITHUB_RUN_URL}"
          curl -X POST -H 'Content-type: application/json' \
          --data "{\"text\": \"${MESSAGE}\"}" \
          ${SLACK_WEBHOOK_URL}

      - name: Derive Short Commit
        id: commit_info
        run: |
          short_commit=$(echo "${GITHUB_SHA}" | cut -c1-7)
          echo "short_commit=$short_commit" >> $GITHUB_OUTPUT

      - name: Report Benchmark Results to Slack
        uses: slackapi/slack-github-action@v2
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_OAUTH_TOKEN }}
          payload: |
            channel: ${{ secrets.SLACK_BENCHMARKS_CHANNEL_ID }}
            text: |
              *<${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ steps.commit_info.outputs.short_commit }}>*: Community "${{ matrix.dataset}}" Query Results available:
              <https://paradedb.github.io/paradedb/benchmarks/>
          errors: true
          retries: 5
