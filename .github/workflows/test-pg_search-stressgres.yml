# workflows/test-pg_search-stressgres.yml
#
# Test pg_search Stressgres
# Run the Stressgres stress testing against pg_search.

name: Test pg_search Stressgres

# We run benchmarks on `main`, and on `perf` PRs.
on:
  push:
    branches:
      - main
    paths:
      - ".github/stressgres/**"
      - ".github/workflows/test-pg_search-stressgres.yml"
      - "**/*.rs"
      - "**/*.toml"
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    branches:
      - main
  workflow_dispatch:
    inputs:
      commit:
        description: "A specific commit hash or tag to benchmark.  Uses `main` if not specified."
        required: false
        default: ""

permissions:
  contents: write
  deployments: write
  pull-requests: write

concurrency:
  # If this is a manual backfill run, use the commit SHA.
  # Otherwise (push/PR) fall back to the branch name.
  group: ${{ format('stressgres-benchmarks-{0}',
    (github.event_name == 'workflow_dispatch' && inputs.commit) || github.ref) }}
  # Keep auto-cancellation for normal CI, switch it off for backfills.
  cancel-in-progress: ${{ github.event_name != 'workflow_dispatch' }}

jobs:
  test-pg_search-stressgres:
    name: Run Stressgres ${{ matrix.test_file }} on pg_search
    runs-on: ubicloud-premium-30-ubuntu-2404
    strategy:
      matrix:
        test_file: [single-server.toml, bulk-updates.toml, wide-table.toml]
    env:
      pg_version: 17

    steps:
      - name: Determine ref to benchmark
        id: determine-ref
        run: |
          # Use a workflow-provided commit (if any), else a PR's head ref, else the main branch.
          REF=${{ inputs.commit || (github.event_name == 'pull_request' && github.head_ref) || 'main' }}
          echo "::set-output name=ref::$REF"

      - name: Checkout Git Repository at ref=${{ steps.determine-ref.outputs.ref }}
        uses: actions/checkout@v4
        with:
          path: paradedb
          ref: ${{ steps.determine-ref.outputs.ref }}

      # We manually fetch the stressgres queries from `main` to make sure all are available when backfilling
      # old commits potentially created before new queries were added.
      - name: Fetch the Latest Stressgres Jobs
        run: |
          ls -la
          git clone --depth 1 --branch main https://github.com/paradedb/paradedb.git paradedb-temp
          cp -rv paradedb-temp/.github/stressgres paradedb/.github/
          rm -rf paradedb-temp

          echo "Copied stressgres jobs:"
          ls -la paradedb/.github/stressgres/

      - name: Install Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Extract pgrx Version
        id: pgrx
        working-directory: paradedb/pg_search/
        run: |
          version=$(cargo tree --depth 1 -i pgrx -p pg_search | head -n 1 | sed -E 's/.*v([0-9]+\.[0-9]+\.[0-9]+).*/\1/')
          echo "version=$version" >> $GITHUB_OUTPUT

      # Caches from base branches are available to PRs, but not across unrelated branches,
      # so we only save the cache on the default branch, but load it on all branches.
      - name: Install Rust Cache
        uses: swatinem/rust-cache@v2
        with:
          prefix-key: "v1-rust"
          key: ${{ env.pg_version }}-${{ steps.pgrx.outputs.version }}
          cache-targets: true
          cache-all-crates: true
          save-if: ${{ github.ref == 'refs/heads/main' }}

      - name: Install required system tools
        run: sudo apt-get update && sudo apt-get install -y lsof fontconfig pkg-config libfontconfig1-dev

      - name: Install llvm-tools-preview
        run: rustup component add llvm-tools-preview

      - name: Derive Short Commit
        id: commit_info
        run: |
          short_commit=$(echo "${GITHUB_SHA}" | cut -c1-7)
          echo "short_commit=$short_commit" >> $GITHUB_OUTPUT

      - name: Install & Configure Supported PostgreSQL Version
        run: |
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          sudo apt-get update && sudo apt-get install -y postgresql-${{ env.pg_version }} postgresql-server-dev-${{ env.pg_version }}
          echo "/usr/lib/postgresql/${{ env.pg_version }}/bin" >> $GITHUB_PATH

      - name: Install cargo-pgrx
        run: cargo install -j $(nproc) --locked cargo-pgrx --version ${{ steps.pgrx.outputs.version }} --debug

      - name: Initialize cargo-pgrx environment
        run: cargo pgrx init --pg${{ env.pg_version }}=`which pg_config`

      - name: Checkout Stressgres Repo
        uses: actions/checkout@v4
        with:
          repository: paradedb/stressgres
          path: stressgres
          token: ${{ secrets.GHA_CREATE_RELEASE_PAT }}

      - name: Compile & install pg_search extension
        working-directory: paradedb/pg_search/
        run: cargo pgrx install --sudo --release --pg-config `which pg_config` --features=pg${{ env.pg_version }},icu --no-default-features

      - name: Run Stressgres Test Suite
        working-directory: stressgres/
        run: |
          sudo chmod a+rwx /var/run/postgresql/ && \
          cargo run --release -- headless \
          /home/runner/work/paradedb/paradedb/paradedb/.github/stressgres/${{ matrix.test_file }} \
          --log-file stressgres-${{ matrix.test_file }}.log \
          --runtime 600000

      - name: Generate Stressgres Continuous Benchmarking Metrics
        working-directory: stressgres/
        run: cargo run --release -- csv stressgres-${{ matrix.test_file }}.log output.csv

      # This is where we can configure how the different runs are aggregated
      # into multiple JSON files for plotting in our continuous benchmarks.
      #
      # tps values are pulled out separately as they're "bigger-is-better" whereas everything else
      # is "smaller-is-better"
      - name: Generate pg_search Continuous Benchmarking Metrics
        shell: python {0}
        run: |
          import csv, json
          tps_metrics = []
          other_metrics = []
          with open('stressgres/output.csv', 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
              metric = {
                "name":     f"{row['job_title']} - {row['server_name']} - {row['metric_name']}",
                "unit":     f"median {row['metric_name']}",
                "value":    float(row['median']),
                "extra":    f"avg {row['metric_name']}: {float(row['avg'])}, max {row['metric_name']}: {float(row['max'])}, count: {int(row['count'])}",
              }
              if row['metric_name'] == 'tps':
                tps_metrics.append(metric)
              else:
                other_metrics.append(metric)

          tps_metrics.sort(key=lambda metric: metric['name'])
          other_metrics.sort(key=lambda metric: metric['name'])

          with open('stressgres/pg_search_tps.json', 'w') as out:
              json.dump(tps_metrics, out)
          with open('stressgres/pg_search_other.json', 'w') as out:
              json.dump(other_metrics, out)

      # we sleep for a random number of seconds to hopefully avoid conflicting with other concurrent
      # benchmark-action publish actions running in other jobs
      - name: Sleep
        run: |
          LOW=1
          HIGH=66
          sleep $(( $LOW + RANDOM % ( $HIGH - $LOW + 1 ) ))

      - name: Check and Publish Continuous Benchmarking Metrics - TPS
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: "pg_search ${{ matrix.test_file }} Performance - TPS"
          ref: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
          tool: "customBiggerIsBetter"
          output-file-path: "stressgres/pg_search_tps.json"
          github-token: ${{ secrets.GHA_CREATE_RELEASE_PAT }}
          gh-repository: "github.com/paradedb/paradedb"
          auto-push: ${{ github.event_name != 'pull_request' }}
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: stressgres
          alert-threshold: "110%"
          # NB: We comment and alert rather than failing, as we have both Github and Slack messages
          # to notify us.
          comment-on-alert: true
          alert-comment-cc-users: "@${{ github.actor }}"
          comment-always: ${{ github.event_name == 'pull_request' }}

      - name: Cleanup Previous Benchmark Publish Working Directory
        run: |
          rm -rf ./benchmark-data-repository

      # we sleep for a random number of seconds to hopefully avoid conflicting with other concurrent
      # benchmark-action publish actions running in other jobs
      - name: Sleep
        run: |
          LOW=1
          HIGH=66
          sleep $(( $LOW + RANDOM % ( $HIGH - $LOW + 1 ) ))

      - name: Check and Publish Continuous Benchmarking Metrics - Other
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: "pg_search ${{ matrix.test_file }} Performance - Other Metrics"
          ref: ${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}
          tool: "customSmallerIsBetter"
          output-file-path: "stressgres/pg_search_other.json"
          github-token: ${{ secrets.GHA_CREATE_RELEASE_PAT }}
          gh-repository: "github.com/paradedb/paradedb"
          auto-push: ${{ github.event_name != 'pull_request' }}
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: stressgres
          alert-threshold: "110%"
          # NB: We comment and alert rather than failing, as we have both Github and Slack messages
          # to notify us.
          comment-on-alert: true
          alert-comment-cc-users: "@${{ github.actor }}"
          comment-always: ${{ github.event_name == 'pull_request' }}

      - name: Create Stressgres Graph
        working-directory: stressgres/
        run: cargo run --release -- graph stressgres-${{ matrix.test_file }}.log stressgres-${{ matrix.test_file }}-${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}.png

      - name: Upload Stressgres Graph
        id: artifact-graph
        uses: actions/upload-artifact@v4
        with:
          name: stressgres-graph-${{ matrix.test_file }}
          path: stressgres/stressgres-${{ matrix.test_file }}-${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}.png

      - name: Upload Stressgres Logs
        id: artifact-logs
        uses: actions/upload-artifact@v4
        with:
          name: stressgres-logs-${{ matrix.test_file }}
          path: stressgres/stressgres-${{ matrix.test_file }}.log

      - name: Upload Stressgres Graphs to Slack
        if: github.event_name != 'pull_request'
        uses: slackapi/slack-github-action@v2
        with:
          method: files.uploadV2
          token: ${{ secrets.SLACK_OAUTH_TOKEN }}
          payload: |
            channel_id: ${{ secrets.SLACK_BENCHMARKS_CHANNEL_ID }}
            initial_comment: |
              *<${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}>*: Community Stressgres "${{ matrix.test_file }}" Results available (<${{ steps.artifact-logs.outputs.artifact-url }} | logs>):
              <https://paradedb.github.io/paradedb/stressgres/>
            file: "stressgres/stressgres-${{ matrix.test_file }}-${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}.png"
            filename: "stressgres-${{ matrix.test_file }}-${{ steps.determine-ref.outputs.ref || steps.commit_info.outputs.short_commit }}.png"
            request_file_info: true
          errors: true
          payload-templated: false
          retries: 5

      - name: Print Postgres Logs
        run: |
          for f in `ls /tmp/stressgres/*.log`; do
            echo $f
            cat $f
          done

      - name: Notify Slack on Failure
        if: failure() && github.event_name == 'push'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_GITHUB_CHANNEL_WEBHOOK_URL }}
        run: |
          GITHUB_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          ARTIFACT_URL="${{ steps.artifact-logs.outputs.artifact-url }}"
          MESSAGE="<!here> \`test-pg_search-stressgres\` workflow (${{ matrix.test_file }}) failed in \`paradedb/paradedb\` -- investigate immediately! GitHub Action Logs: ${GITHUB_RUN_URL} | Stressgres Log: ${ARTIFACT_URL}"
          curl -X POST -H 'Content-type: application/json' \
          --data "{\"text\": \"${MESSAGE}\"}" \
          ${SLACK_WEBHOOK_URL}
