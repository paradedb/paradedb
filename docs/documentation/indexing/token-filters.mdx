---
title: Token Filters
noindex: true
---

Token filters apply additional processing to tokens after they have been created.

## Stemmer

Stemming is the process of reducing words to their root form. In English, for example, the root form of `running` and `runs` is `run`. The `stemmer` filter can
be applied to any tokenizer.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "stemmer": "English"}}
    }'
);
```

<ParamField body="stemmer">
  Available stemmers are `Arabic`, `Danish`, `Dutch`, `English`, `Finnish`,
  `French`, `German`, `Greek`, `Hungarian`, `Italian`, `Norwegian`,
  `Portuguese`, `Romanian`, `Russian`, `Spanish`, `Swedish`, `Tamil`, and
  `Turkish`.
</ParamField>

## Remove Long

The `remove_long` filter removes all tokens longer than a fixed number of bytes. If not specified,
`remove_long` defaults to `255`.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "remove_long": 255}}
    }'
);
```

## Lowercase

The `lowercase` filter lowercases all tokens. If not specified, `lowercase` defaults to `true`.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "lowercase": false}}
    }'
);
```

## Stopwords Language

<Note>This filter is not supported for the ngram tokenizer.</Note>

`stopwords_language` removes common "stop words" for a specific language from the original text before tokenization.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "stopwords_language": "English"}}
    }'
);
```

<ParamField body="stopwords_language">
  Available languages are `Danish`, `Dutch`, `English`, `Finnish`, `French`,
  `German`, `Hungarian`, `Italian`, `Norwegian`, `Portuguese`, `Russian`,
  `Spanish`, and `Swedish`.
</ParamField>

## Custom Stopwords

<Note>This filter is not supported for the ngram tokenizer.</Note>

`stopwords` removes custom words from the original text before tokenization.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "stopwords": ["shoes", "boots"]}}
    }'
);
```

## ASCII Folding

The ASCII folding filter strips away diacritical marks (accents, umlauts, tildes, etc.) while leaving the base character intact.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "default", "ascii_folding": true}}
    }'
);
```

## Trim

The `trim` filter removes leading and trailing whitespace from each token. After trimming, tokens that become empty are filtered out.
This filter maps to Elasticsearch's trim token filter and is particularly useful for tokenizers like Jieba and Lindera that may produce
whitespace-only tokens or tokens with surrounding whitespace.

```sql
CREATE INDEX search_idx ON mock_items
USING bm25 (id, description)
WITH (
    key_field='id',
    text_fields='{
        "description": {"tokenizer": {"type": "jieba", "trim": true}}
    }'
);
```

The filter works with all tokenizers. Here are some examples:

```sql
-- With Jieba (Chinese)
SELECT '富裕 劳动力'::pdb.jieba('trim=true')::text[];
-- Returns: {富裕,劳动,动力,劳动力} (no space token)

-- With Lindera (Chinese)
SELECT '富裕 劳动力'::pdb.lindera('chinese', 'trim=true')::text[];
-- Returns: {富裕,劳动力} (no space token)

-- With Lindera (Korean)
SELECT '아름다운 우리나라'::pdb.lindera('korean', 'trim=true')::text[];
-- Returns Korean tokens without spaces
```

<Note>
  The `trim` filter detects all Unicode whitespace characters, not just spaces.
  This includes tabs, newlines, and other Unicode whitespace as defined by the
  Unicode standard.
</Note>
