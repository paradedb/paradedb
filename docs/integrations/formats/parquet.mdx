---
title: Parquet
---

## Overview

This code block demonstrates how to query Parquet file(s).

```sql
CREATE FOREIGN DATA WRAPPER <wrapper_name>
HANDLER parquet_fdw_handler
VALIDATOR parquet_fdw_validator;

CREATE SERVER <server_name>
FOREIGN DATA WRAPPER <wrapper_name>;

CREATE FOREIGN TABLE <table_name> ()
SERVER <server_name>
OPTIONS (files '<files>');
```

<Accordion title="Example Usage">
```sql
CREATE FOREIGN DATA WRAPPER parquet_wrapper
HANDLER parquet_fdw_handler
VALIDATOR parquet_fdw_validator;

CREATE SERVER parquet_server
FOREIGN DATA WRAPPER parquet_wrapper;

CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (files 's3://bucket/folder/file.parquet');

````
</Accordion>

<ParamField body="wrapper_name" required>
  Foreign data wrapper name. Can be any string.
</ParamField>
<ParamField body="server_name" required>
  Foreign server name. Can be any string.
</ParamField>
<ParamField body="table_name" required>
  Foreign table name. Can be any string.
</ParamField>
<ParamField body="files" required>
The path of a single Parquet file or [multiple Parquet files](#multiple-parquet-files).
For instance, `s3://bucket/folder/file.parquet` if the file is in Amazon S3, `https://domain.tld/file.parquet`
if the file is on a HTTP server, or `/path/to/file.parquet` if the file is on the local file system.
</ParamField>

## Parquet Options

There are a number of options that can be passed into the `CREATE FOREIGN TABLE` statement.
These are the same [options](https://duckdb.org/docs/data/parquet/overview#parameters) accepted
by DuckDB's `read_parquet` function.

```sql
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files 's3://bucket/folder/file.parquet',
    binary_as_string 'true',
    hive_partitioning 'true'
);
````

<ParamField body="files" required>
The path of a single Parquet file or [multiple Parquet files](#multiple-parquet-files).
For instance, `s3://bucket/folder/file.parquet` if the file is in Amazon S3 or `/path/to/file.parquet`
if the file is on the local file system.
</ParamField>
<ParamField body="binary_as_string" default="false">
Parquet files generated by legacy writers do not correctly set the `UTF8` flag for strings,
causing string columns to be loaded as `BLOB` instead. Set this to true to load binary columns as
strings.
</ParamField>
<ParamField body="filename" default="false">
Whether or not an extra `filename` column should be included in the result.
</ParamField>
<ParamField body="file_row_number" default="false">
Whether or not to include the `file_row_number` column.
</ParamField>
<ParamField body="hive_partitioning" default="false">
Whether or not to interpret the path as a Hive partitioned path.
</ParamField>
<ParamField body="hive_types">
If `hive_partitioning` is enabled, `hive_types` can be used to specify the logical types of the hive
partitions in a struct.
<Accordion title="Example Usage">
```sql
-- Dollar-quoted strings are used to contain single quotes
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files 's3://bucket/folder/file.parquet',
    hive_partitioning 'true',
    hive_types $${'release': DATE, 'orders': BIGINT}$$
);
```
</Accordion>
</ParamField>
<ParamField body="hive_types_autocast">
hive_types will be autodetected for the following types: `DATE`, `TIMESTAMP` and `BIGINT`.
To switch off the autodetection, this option can be set to `0`.
<Accordion title="Example Usage">
```sql
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files 's3://bucket/folder/file.parquet',
    hive_partitioning 'true',
    hive_types $${'release': DATE, 'orders': BIGINT}$$,
    hive_types_autocast '0'
);
```
</Accordion>
</ParamField>
<ParamField body="union_by_name" default="false">
Whether the columns of multiple schemas should be unified by name, rather than by position.
</ParamField>

## Multiple Parquet Files

To treat multiple Parquet files as a single table, their paths should be passed in as a comma-separated
string.

```sql
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files '/path/to/file1.parquet, /path/to/file2.parquet'
);
```

To treat a directory of Parquet files as a single table, the glob pattern should be used.

```sql
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files '/folder/*.parquet',
);
```

The glob pattern can also be used to read all Parquet files from multiple directories.

```sql
CREATE FOREIGN TABLE parquet_table ()
SERVER parquet_server
OPTIONS (
    files '/folder1/*.parquet, /folder2/*.parquet'
);
```

## Parquet Schema

The `parquet_describe` function returns the column names and types contained within a Parquet file. This function is useful
for determining the schema of the Postgres foreign table.

```sql
SELECT * FROM parquet_describe('/path/to/file.parquet')
```

The `parquet_schema` function returns the internal schema contained within the metadata of a Parquet file.

```sql
SELECT * FROM parquet_schema('/path/to/file.parquet');
```

## Cloud Object Stores

The [object stores](/integrations/object_stores) documentation explains how to provide secrets and other credentials for
Parquet files stored in object stores like S3.
