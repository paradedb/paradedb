-- Test custom agg function with pdb.agg()
CREATE EXTENSION IF NOT EXISTS pg_search;
SET paradedb.enable_aggregate_custom_scan TO on;
DROP TABLE IF EXISTS logs CASCADE;
-- Setup test data
CREATE TABLE logs (
    id SERIAL PRIMARY KEY,
    description TEXT,
    severity TEXT,
    category TEXT,
    response_time INT,
    status_code INT,
    timestamp TIMESTAMP
);
INSERT INTO logs (description, severity, category, response_time, status_code, timestamp) VALUES
    -- Database errors
    ('Database connection error', 'error', 'database', 150, 500, '2024-01-01 10:00:00'),
    ('Invalid query syntax error', 'error', 'database', 50, 400, '2024-01-01 10:03:00'),
    ('Database timeout error', 'critical', 'database', 3000, 503, '2024-01-01 10:05:00'),
    ('Database deadlock detected', 'error', 'database', 200, 500, '2024-01-01 10:10:00'),
    ('Database connection pool exhausted', 'critical', 'database', 5000, 503, '2024-01-01 10:15:00'),
    ('Slow database query', 'warning', 'database', 2500, 200, '2024-01-01 10:20:00'),
    
    -- API errors
    ('Failed to fetch data', 'error', 'api', 200, 404, '2024-01-01 10:01:00'),
    ('API rate limit exceeded', 'warning', 'api', 100, 429, '2024-01-01 10:06:00'),
    ('API authentication failed', 'error', 'api', 80, 401, '2024-01-01 10:11:00'),
    ('API endpoint not found', 'error', 'api', 50, 404, '2024-01-01 10:16:00'),
    ('API internal server error', 'critical', 'api', 1500, 500, '2024-01-01 10:21:00'),
    
    -- Network errors
    ('Timeout connecting to service', 'error', 'network', 5000, 503, '2024-01-01 10:02:00'),
    ('Network connection refused', 'error', 'network', 100, 503, '2024-01-01 10:07:00'),
    ('DNS resolution failed', 'error', 'network', 30, 503, '2024-01-01 10:12:00'),
    ('Network timeout error', 'critical', 'network', 10000, 504, '2024-01-01 10:17:00'),
    
    -- Application errors
    ('Application crashed', 'critical', 'application', 0, 500, '2024-01-01 10:04:00'),
    ('Memory allocation error', 'critical', 'application', 10, 500, '2024-01-01 10:08:00'),
    ('Null pointer exception', 'error', 'application', 5, 500, '2024-01-01 10:13:00'),
    ('Stack overflow error', 'critical', 'application', 2, 500, '2024-01-01 10:18:00'),
    
    -- Security errors
    ('Unauthorized access attempt', 'warning', 'security', 20, 403, '2024-01-01 10:09:00'),
    ('Invalid authentication token', 'error', 'security', 15, 401, '2024-01-01 10:14:00'),
    ('Suspicious activity detected', 'critical', 'security', 25, 403, '2024-01-01 10:19:00');
CREATE INDEX logs_idx ON logs USING bm25 (id, description, severity, category, response_time, status_code, timestamp)
WITH (
    key_field = 'id',
    text_fields = '{"description": {}, "severity": {"fast": true}, "category": {"fast": true}}',
    numeric_fields = '{"response_time": {"fast": true}, "status_code": {"fast": true}}',
    datetime_fields = '{"timestamp": {"fast": true}}'
);
-- Test 1: Simple custom agg with terms aggregation (without search query - should fail gracefully or not be intercepted)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
  category   |                                                                       agg                                                                        
-------------+--------------------------------------------------------------------------------------------------------------------------------------------------
 database    | {"buckets": [{"key": "error", "doc_count": 2}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 application | {"buckets": [{"key": "critical", "doc_count": 2}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 api         | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 network     | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(4 rows)

-- Test 2: Custom agg in window function
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                              QUERY PLAN                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
(11 rows)

SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
 id |        description         | severity |  category   | response_time | status_code |        timestamp         |             agg              
----+----------------------------+----------+-------------+---------------+-------------+--------------------------+------------------------------
 11 | API internal server error  | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"value": 2101.714285714286}
 19 | Stack overflow error       | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 | {"value": 2101.714285714286}
 15 | Network timeout error      | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"value": 2101.714285714286}
 17 | Memory allocation error    | critical | application |            10 |         500 | Mon Jan 01 10:08:00 2024 | {"value": 2101.714285714286}
  3 | Database timeout error     | critical | database    |          3000 |         503 | Mon Jan 01 10:05:00 2024 | {"value": 2101.714285714286}
  2 | Invalid query syntax error | error    | database    |            50 |         400 | Mon Jan 01 10:03:00 2024 | {"value": 2101.714285714286}
  1 | Database connection error  | error    | database    |           150 |         500 | Mon Jan 01 10:00:00 2024 | {"value": 2101.714285714286}
(7 rows)

-- Test 3: Mix custom and standard aggregates
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, 
       COUNT(*),
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('COUNT(*)'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: COUNT(*), CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, 
       COUNT(*),
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
  category   | count |                                                                       agg                                                                        
-------------+-------+--------------------------------------------------------------------------------------------------------------------------------------------------
 database    |     3 | {"buckets": [{"key": "error", "doc_count": 2}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 application |     2 | {"buckets": [{"key": "critical", "doc_count": 2}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 api         |     1 | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 network     |     1 | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(4 rows)

-- Test 4: Custom agg with FILTER (extracted at planning time)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) 
       FILTER (WHERE status_code >= 500)
FROM logs
WHERE description @@@ 'error';
                                                                                                                                  QUERY PLAN                                                                                                                                   
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Aggregate Definition: {"0":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"filter":{"range":{"field":"status_code","is_datetime":false,"lower_bound":{"included":500},"upper_bound":null}}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) 
       FILTER (WHERE status_code >= 500)
FROM logs
WHERE description @@@ 'error';
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 5: Custom agg with FILTER and OVER (window function)
-- NOTE: FILTER with window functions is currently not supported
-- This test documents the current limitation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *, pdb.agg('{"terms": {"field": "category"}}'::jsonb) 
       FILTER (WHERE status_code >= 500) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() with FILTER clause is not currently supported. FILTER with window functions requires the 'WINDOW_AGG_FILTER_CLAUSE' feature flag to be enabled. Try removing the FILTER clause or use a standard aggregate function instead. See https://github.com/paradedb/paradedb/issues for more information.
-- This query is expected to fail because FILTER with OVER is not yet supported
-- The error message guides users to file an issue or use paradedb.all()
SELECT *, pdb.agg('{"terms": {"field": "category"}}'::jsonb) 
       FILTER (WHERE status_code >= 500) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() with FILTER clause is not currently supported. FILTER with window functions requires the 'WINDOW_AGG_FILTER_CLAUSE' feature flag to be enabled. Try removing the FILTER clause or use a standard aggregate function instead. See https://github.com/paradedb/paradedb/issues for more information.
-- Test 6: EXPLAIN query to show custom agg is recognized
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, 
       COUNT(*),
       pdb.agg('{"max": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                              QUERY PLAN                                                                              
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('COUNT(*)'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: COUNT(*), CUSTOM_AGG({"max":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"max":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, 
       COUNT(*),
       pdb.agg('{"max": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 7: pdb.agg() without @@@ operator (no WHERE clause)
-- This tests that pdb.agg() is intercepted even without search operator
-- The custom scan is now used because we detect window aggregates
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                              QUERY PLAN                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Full Index Scan: true
         Tantivy Query: "all"
(12 rows)

-- Execute the query - should work now with custom scan
SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
ORDER BY timestamp DESC LIMIT 10;
 id |            description             | severity |  category   | response_time | status_code |        timestamp         |             agg              
----+------------------------------------+----------+-------------+---------------+-------------+--------------------------+------------------------------
 11 | API internal server error          | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"value": 1274.409090909091}
  6 | Slow database query                | warning  | database    |          2500 |         200 | Mon Jan 01 10:20:00 2024 | {"value": 1274.409090909091}
 22 | Suspicious activity detected       | critical | security    |            25 |         403 | Mon Jan 01 10:19:00 2024 | {"value": 1274.409090909091}
 19 | Stack overflow error               | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 | {"value": 1274.409090909091}
 15 | Network timeout error              | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"value": 1274.409090909091}
 10 | API endpoint not found             | error    | api         |            50 |         404 | Mon Jan 01 10:16:00 2024 | {"value": 1274.409090909091}
  5 | Database connection pool exhausted | critical | database    |          5000 |         503 | Mon Jan 01 10:15:00 2024 | {"value": 1274.409090909091}
 21 | Invalid authentication token       | error    | security    |            15 |         401 | Mon Jan 01 10:14:00 2024 | {"value": 1274.409090909091}
 18 | Null pointer exception             | error    | application |             5 |         500 | Mon Jan 01 10:13:00 2024 | {"value": 1274.409090909091}
 14 | DNS resolution failed              | error    | network     |            30 |         503 | Mon Jan 01 10:12:00 2024 | {"value": 1274.409090909091}
(10 rows)

-- Test 8: pdb.agg() with simple WHERE condition (not @@@)
-- This tests that pdb.agg() works with regular WHERE conditions
-- The custom scan should be used because we have window aggregates
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
WHERE status_code >= 500
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                              QUERY PLAN                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Tantivy Query: {"range":{"field":"status_code","lower_bound":{"included":500},"upper_bound":null,"is_datetime":false}}
(11 rows)

-- Execute the query - should work with custom scan
SELECT *, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER ()
FROM logs
WHERE status_code >= 500
ORDER BY timestamp DESC LIMIT 10;
 id |            description             | severity |  category   | response_time | status_code |        timestamp         |              agg              
----+------------------------------------+----------+-------------+---------------+-------------+--------------------------+-------------------------------
 11 | API internal server error          | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"value": 1922.8461538461538}
 19 | Stack overflow error               | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 | {"value": 1922.8461538461538}
 15 | Network timeout error              | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"value": 1922.8461538461538}
  5 | Database connection pool exhausted | critical | database    |          5000 |         503 | Mon Jan 01 10:15:00 2024 | {"value": 1922.8461538461538}
 18 | Null pointer exception             | error    | application |             5 |         500 | Mon Jan 01 10:13:00 2024 | {"value": 1922.8461538461538}
 14 | DNS resolution failed              | error    | network     |            30 |         503 | Mon Jan 01 10:12:00 2024 | {"value": 1922.8461538461538}
  4 | Database deadlock detected         | error    | database    |           200 |         500 | Mon Jan 01 10:10:00 2024 | {"value": 1922.8461538461538}
 17 | Memory allocation error            | critical | application |            10 |         500 | Mon Jan 01 10:08:00 2024 | {"value": 1922.8461538461538}
 13 | Network connection refused         | error    | network     |           100 |         503 | Mon Jan 01 10:07:00 2024 | {"value": 1922.8461538461538}
  3 | Database timeout error             | critical | database    |          3000 |         503 | Mon Jan 01 10:05:00 2024 | {"value": 1922.8461538461538}
(10 rows)

-- Test 9: Error handling - invalid JSON with 'buckets' wrapper (should fail fast)
SELECT *, pdb.agg('{"buckets": {"terms": {"field": "category"}}}'::jsonb) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() received JSON with 'buckets' key. Remove the 'buckets' wrapper - pdb.agg() expects a single aggregation definition. Example: {"terms": {"field": "country"}} instead of {"buckets": {"terms": {"field": "country"}}}
-- Test 10: Error handling - non-object JSON (should fail fast)
SELECT *, pdb.agg('"invalid"'::jsonb) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() expects a JSON object representing a Tantivy aggregation. Example: {"terms": {"field": "country"}}
-- Test 11: Error handling - invalid aggregation type (should fail fast)
SELECT *, pdb.agg('{"invalid_agg_type": {"field": "category"}}'::jsonb) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() received unknown aggregation type 'invalid_agg_type'. Valid types: terms, range, histogram, date_histogram, filter, avg, sum, min, max, count, stats, percentiles. Example: {"terms": {"field": "country"}}
-- Test 12: Error handling - pdb.agg() with FILTER clause (should fail at planner hook)
SELECT *, pdb.agg('{"terms": {"field": "category"}}'::jsonb) FILTER (WHERE status_code >= 500) OVER ()
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
ERROR:  pdb.agg() with FILTER clause is not currently supported. FILTER with window functions requires the 'WINDOW_AGG_FILTER_CLAUSE' feature flag to be enabled. Try removing the FILTER clause or use a standard aggregate function instead. See https://github.com/paradedb/paradedb/issues for more information.
-- =====================================================================
-- SECTION 2: pdb.agg() with Different Aggregation Types (GROUP BY)
-- =====================================================================
-- Test 13: pdb.agg() with range aggregation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"range": {"field": "response_time", "ranges": [{"to": 100}, {"from": 100, "to": 1000}, {"from": 1000}]}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                                                QUERY PLAN                                                                                                                
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"range":{"field":"response_time","ranges":[{"to":100},{"to":1000,"from":100},{"from":1000}]}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"range":{"field":"response_time","keyed":false,"ranges":[{"to":100.0},{"from":100.0,"to":1000.0},{"from":1000.0}]}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"range": {"field": "response_time", "ranges": [{"to": 100}, {"from": 100, "to": 1000}, {"from": 1000}]}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
  category   |                                                                                        agg                                                                                        
-------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 database    | {"buckets": [{"to": 100.0, "key": "*-100", "doc_count": 1}, {"to": 1000.0, "key": "100-1000", "from": 100.0, "doc_count": 1}, {"key": "1000-*", "from": 1000.0, "doc_count": 1}]}
 application | {"buckets": [{"to": 100.0, "key": "*-100", "doc_count": 2}, {"to": 1000.0, "key": "100-1000", "from": 100.0, "doc_count": 0}, {"key": "1000-*", "from": 1000.0, "doc_count": 0}]}
 api         | {"buckets": [{"to": 100.0, "key": "*-100", "doc_count": 0}, {"to": 1000.0, "key": "100-1000", "from": 100.0, "doc_count": 0}, {"key": "1000-*", "from": 1000.0, "doc_count": 1}]}
 network     | {"buckets": [{"to": 100.0, "key": "*-100", "doc_count": 0}, {"to": 1000.0, "key": "100-1000", "from": 100.0, "doc_count": 0}, {"key": "1000-*", "from": 1000.0, "doc_count": 1}]}
(4 rows)

-- Test 14: pdb.agg() with histogram aggregation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"histogram": {"field": "response_time", "interval": 100}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
                                                                                                                                  QUERY PLAN                                                                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"histogram":{"field":"response_time","interval":100}})
     Aggregate Definition: {"0":{"histogram":{"extended_bounds":null,"field":"response_time","hard_bounds":null,"interval":100.0,"is_normalized_to_ns":false,"keyed":false,"min_doc_count":null,"offset":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"histogram": {"field": "response_time", "interval": 100}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   agg                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"key": 0.0, "doc_count": 3}, {"key": 100.0, "doc_count": 1}, {"key": 200.0, "doc_count": 0}, {"key": 300.0, "doc_count": 0}, {"key": 400.0, "doc_count": 0}, {"key": 500.0, "doc_count": 0}, {"key": 600.0, "doc_count": 0}, {"key": 700.0, "doc_count": 0}, {"key": 800.0, "doc_count": 0}, {"key": 900.0, "doc_count": 0}, {"key": 1000.0, "doc_count": 0}, {"key": 1100.0, "doc_count": 0}, {"key": 1200.0, "doc_count": 0}, {"key": 1300.0, "doc_count": 0}, {"key": 1400.0, "doc_count": 0}, {"key": 1500.0, "doc_count": 1}, {"key": 1600.0, "doc_count": 0}, {"key": 1700.0, "doc_count": 0}, {"key": 1800.0, "doc_count": 0}, {"key": 1900.0, "doc_count": 0}, {"key": 2000.0, "doc_count": 0}, {"key": 2100.0, "doc_count": 0}, {"key": 2200.0, "doc_count": 0}, {"key": 2300.0, "doc_count": 0}, {"key": 2400.0, "doc_count": 0}, {"key": 2500.0, "doc_count": 0}, {"key": 2600.0, "doc_count": 0}, {"key": 2700.0, "doc_count": 0}, {"key": 2800.0, "doc_count": 0}, {"key": 2900.0, "doc_count": 0}, {"key": 3000.0, "doc_count": 1}, {"key": 3100.0, "doc_count": 0}, {"key": 3200.0, "doc_count": 0}, {"key": 3300.0, "doc_count": 0}, {"key": 3400.0, "doc_count": 0}, {"key": 3500.0, "doc_count": 0}, {"key": 3600.0, "doc_count": 0}, {"key": 3700.0, "doc_count": 0}, {"key": 3800.0, "doc_count": 0}, {"key": 3900.0, "doc_count": 0}, {"key": 4000.0, "doc_count": 0}, {"key": 4100.0, "doc_count": 0}, {"key": 4200.0, "doc_count": 0}, {"key": 4300.0, "doc_count": 0}, {"key": 4400.0, "doc_count": 0}, {"key": 4500.0, "doc_count": 0}, {"key": 4600.0, "doc_count": 0}, {"key": 4700.0, "doc_count": 0}, {"key": 4800.0, "doc_count": 0}, {"key": 4900.0, "doc_count": 0}, {"key": 5000.0, "doc_count": 0}, {"key": 5100.0, "doc_count": 0}, {"key": 5200.0, "doc_count": 0}, {"key": 5300.0, "doc_count": 0}, {"key": 5400.0, "doc_count": 0}, {"key": 5500.0, "doc_count": 0}, {"key": 5600.0, "doc_count": 0}, {"key": 5700.0, "doc_count": 0}, {"key": 5800.0, "doc_count": 0}, {"key": 5900.0, "doc_count": 0}, {"key": 6000.0, "doc_count": 0}, {"key": 6100.0, "doc_count": 0}, {"key": 6200.0, "doc_count": 0}, {"key": 6300.0, "doc_count": 0}, {"key": 6400.0, "doc_count": 0}, {"key": 6500.0, "doc_count": 0}, {"key": 6600.0, "doc_count": 0}, {"key": 6700.0, "doc_count": 0}, {"key": 6800.0, "doc_count": 0}, {"key": 6900.0, "doc_count": 0}, {"key": 7000.0, "doc_count": 0}, {"key": 7100.0, "doc_count": 0}, {"key": 7200.0, "doc_count": 0}, {"key": 7300.0, "doc_count": 0}, {"key": 7400.0, "doc_count": 0}, {"key": 7500.0, "doc_count": 0}, {"key": 7600.0, "doc_count": 0}, {"key": 7700.0, "doc_count": 0}, {"key": 7800.0, "doc_count": 0}, {"key": 7900.0, "doc_count": 0}, {"key": 8000.0, "doc_count": 0}, {"key": 8100.0, "doc_count": 0}, {"key": 8200.0, "doc_count": 0}, {"key": 8300.0, "doc_count": 0}, {"key": 8400.0, "doc_count": 0}, {"key": 8500.0, "doc_count": 0}, {"key": 8600.0, "doc_count": 0}, {"key": 8700.0, "doc_count": 0}, {"key": 8800.0, "doc_count": 0}, {"key": 8900.0, "doc_count": 0}, {"key": 9000.0, "doc_count": 0}, {"key": 9100.0, "doc_count": 0}, {"key": 9200.0, "doc_count": 0}, {"key": 9300.0, "doc_count": 0}, {"key": 9400.0, "doc_count": 0}, {"key": 9500.0, "doc_count": 0}, {"key": 9600.0, "doc_count": 0}, {"key": 9700.0, "doc_count": 0}, {"key": 9800.0, "doc_count": 0}, {"key": 9900.0, "doc_count": 0}, {"key": 10000.0, "doc_count": 1}]}
(1 row)

-- Test 15: pdb.agg() with stats aggregation (multiple metrics)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"stats": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                               QUERY PLAN                                                                               
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"stats":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"stats":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"stats": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  unsupported metric type: Stats(Stats { count: 3, sum: 3200.0, min: Some(50.0), max: Some(3000.0), avg: Some(1066.6666666666667) })
-- Test 16: pdb.agg() with min aggregation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"min": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"min":{"field":"response_time"}})
     Aggregate Definition: {"0":{"min":{"field":"response_time","missing":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"min": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 17: pdb.agg() with max aggregation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"max": {"field": "status_code"}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"max":{"field":"status_code"}})
     Aggregate Definition: {"0":{"max":{"field":"status_code","missing":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"max": {"field": "status_code"}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 18: pdb.agg() with count aggregation
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"count": {"field": "status_code"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  Failed to deserialize custom aggregate: unknown variant `count`, expected one of `range`, `histogram`, `date_histogram`, `terms`, `filter`, `avg`, `value_count`, `max`, `min`, `stats`, `extended_stats`, `sum`, `percentiles`, `top_hits`, `cardinality`
SELECT category, pdb.agg('{"count": {"field": "status_code"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  Failed to deserialize custom aggregate: unknown variant `count`, expected one of `range`, `histogram`, `date_histogram`, `terms`, `filter`, `avg`, `value_count`, `max`, `min`, `stats`, `extended_stats`, `sum`, `percentiles`, `top_hits`, `cardinality`
-- =====================================================================
-- SECTION 3: Multiple pdb.agg() Calls in Same Query
-- =====================================================================
-- Test 19: Multiple pdb.agg() with different aggregation types (GROUP BY)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) AS severity_breakdown
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                               QUERY PLAN                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}}), CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}},"1":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) AS severity_breakdown
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 20: Multiple pdb.agg() without GROUP BY
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"max": {"field": "status_code"}}'::jsonb) AS max_status
FROM logs
WHERE description @@@ 'error';
                                                                                            QUERY PLAN                                                                                            
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}}), CUSTOM_AGG({"max":{"field":"status_code"}})
     Aggregate Definition: {"0":{"avg":{"field":"response_time","missing":null}},"1":{"max":{"field":"status_code","missing":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"max": {"field": "status_code"}}'::jsonb) AS max_status
FROM logs
WHERE description @@@ 'error';
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 21: Mix of standard aggregates and multiple pdb.agg()
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category,
       COUNT(*) AS total_count,
       SUM(response_time) AS total_response_time,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) AS severity_breakdown
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                                                          QUERY PLAN                                                                                                                          
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('COUNT(*)'::text), pdb.agg_fn('SUM'::text), pdb.agg_fn('pdb.AGG'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: COUNT(*), SUM(response_time), CUSTOM_AGG({"avg":{"field":"response_time"}}), CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"sum":{"field":"response_time","missing":null}},"1":{"avg":{"field":"response_time","missing":null}},"2":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category,
       COUNT(*) AS total_count,
       SUM(response_time) AS total_response_time,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) AS avg_response,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) AS severity_breakdown
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- =====================================================================
-- SECTION 4: pdb.agg() with Complex WHERE Clauses
-- =====================================================================
-- Test 22: pdb.agg() with boolean AND in WHERE
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE description @@@ 'error' AND status_code >= 500;
                                                                                                                                     QUERY PLAN                                                                                                                                      
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"boolean":{"must":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}},{"range":{"field":"status_code","lower_bound":{"included":500},"upper_bound":null,"is_datetime":false}}]}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"category"}})
     Aggregate Definition: {"0":{"terms":{"field":"category"}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE description @@@ 'error' AND status_code >= 500;
                                                                                                            agg                                                                                                             
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"key": "application", "doc_count": 2}, {"key": "database", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(1 row)

-- Test 23: pdb.agg() with boolean OR in WHERE
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error' OR description @@@ 'timeout';
                                                                                                                                                     QUERY PLAN                                                                                                                                                      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"boolean":{"should":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}},{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"timeout","lenient":null,"conjunction_mode":null}}}}]}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Aggregate Definition: {"0":{"avg":{"field":"response_time","missing":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error' OR description @@@ 'timeout';
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 24: pdb.agg() with nested boolean expressions
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error' AND status_code >= 500) OR (description @@@ 'timeout' AND response_time > 1000)
GROUP BY category;
                                                                                                                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                                                                                                                      
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"boolean":{"should":[{"boolean":{"must":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}},{"range":{"field":"status_code","lower_bound":{"included":500},"upper_bound":null,"is_datetime":false}}]}},{"boolean":{"must":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"timeout","lenient":null,"conjunction_mode":null}}}},{"range":{"field":"response_time","lower_bound":{"excluded":1000},"upper_bound":null,"is_datetime":false}}]}}]}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error' AND status_code >= 500) OR (description @@@ 'timeout' AND response_time > 1000)
GROUP BY category;
  category   |                                                                       agg                                                                        
-------------+--------------------------------------------------------------------------------------------------------------------------------------------------
 application | {"buckets": [{"key": "critical", "doc_count": 2}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 database    | {"buckets": [{"key": "error", "doc_count": 1}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 network     | {"buckets": [{"key": "error", "doc_count": 1}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 api         | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(4 rows)

-- =====================================================================
-- SECTION 5: pdb.agg() with Empty Results
-- =====================================================================
-- Test 25: pdb.agg() with no matching documents
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE description @@@ 'nonexistent_term_xyz';
                                                                             QUERY PLAN                                                                              
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"nonexistent_term_xyz","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"category"}})
     Aggregate Definition: {"0":{"terms":{"field":"category"}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE description @@@ 'nonexistent_term_xyz';
 agg 
-----
 
(1 row)

-- Test 26: pdb.agg() with GROUP BY and no matching documents
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'nonexistent_term_xyz'
GROUP BY category;
                                                                              QUERY PLAN                                                                              
----------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"nonexistent_term_xyz","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'nonexistent_term_xyz'
GROUP BY category;
 category | agg 
----------+-----
(0 rows)

-- =====================================================================
-- SECTION 6: pdb.agg() with Multiple GROUP BY Columns
-- =====================================================================
-- Test 27: pdb.agg() with two GROUP BY columns
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, severity, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category, severity
ORDER BY category, severity;
                                                                                                                                               QUERY PLAN                                                                                                                                               
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, severity, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category, severity
     Aggregate Definition: {"grouped":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"severity","order":{"_key":"asc"},"segment_size":65000,"size":65000}}},"terms":{"field":"category","order":{"_key":"asc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, severity, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category, severity
ORDER BY category, severity;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 28: pdb.agg() with GROUP BY in different column order
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"terms": {"field": "severity"}}'::jsonb), category
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category;
                                                                                QUERY PLAN                                                                                 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text), category
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","order":{"_key":"asc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT pdb.agg('{"terms": {"field": "severity"}}'::jsonb), category
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category;
                                                                       agg                                                                        |  category   
--------------------------------------------------------------------------------------------------------------------------------------------------+-------------
 {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}                                   | api
 {"buckets": [{"key": "critical", "doc_count": 2}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}                                   | application
 {"buckets": [{"key": "error", "doc_count": 2}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0} | database
 {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}                                   | network
(4 rows)

-- =====================================================================
-- SECTION 7: pdb.agg() Window Functions (TopN)
-- =====================================================================
-- Test 29: Multiple pdb.agg() window functions
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER () AS avg_response,
       pdb.agg('{"max": {"field": "status_code"}}'::jsonb) OVER () AS max_status
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                                                                                                                                 QUERY PLAN                                                                                                                                                                                                                                                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)), (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"max":{"field":"status_code"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text), pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"max":{"field":"status_code"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
(11 rows)

SELECT *,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER () AS avg_response,
       pdb.agg('{"max": {"field": "status_code"}}'::jsonb) OVER () AS max_status
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
 id |        description         | severity |  category   | response_time | status_code |        timestamp         |         avg_response         |    max_status    
----+----------------------------+----------+-------------+---------------+-------------+--------------------------+------------------------------+------------------
 11 | API internal server error  | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
 19 | Stack overflow error       | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
 15 | Network timeout error      | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
 17 | Memory allocation error    | critical | application |            10 |         500 | Mon Jan 01 10:08:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
  3 | Database timeout error     | critical | database    |          3000 |         503 | Mon Jan 01 10:05:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
  2 | Invalid query syntax error | error    | database    |            50 |         400 | Mon Jan 01 10:03:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
  1 | Database connection error  | error    | database    |           150 |         500 | Mon Jan 01 10:00:00 2024 | {"value": 2101.714285714286} | {"value": 504.0}
(7 rows)

-- Test 30: pdb.agg() window function with standard aggregates
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *,
       COUNT(*) OVER () AS total_count,
       pdb.agg('{"terms": {"field": "category"}}'::jsonb) OVER () AS category_breakdown
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                                                                                                           QUERY PLAN                                                                                                                                                                                                                           
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"CountAny":{"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)), (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"terms":{"field":"category"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"CountAny":{"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text), pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"terms":{"field":"category"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
(11 rows)

SELECT *,
       COUNT(*) OVER () AS total_count,
       pdb.agg('{"terms": {"field": "category"}}'::jsonb) OVER () AS category_breakdown
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
 id |        description         | severity |  category   | response_time | status_code |        timestamp         | total_count |                                                                                                     category_breakdown                                                                                                     
----+----------------------------+----------+-------------+---------------+-------------+--------------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 11 | API internal server error  | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 19 | Stack overflow error       | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 15 | Network timeout error      | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 17 | Memory allocation error    | critical | application |            10 |         500 | Mon Jan 01 10:08:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
  3 | Database timeout error     | critical | database    |          3000 |         503 | Mon Jan 01 10:05:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
  2 | Invalid query syntax error | error    | database    |            50 |         400 | Mon Jan 01 10:03:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
  1 | Database connection error  | error    | database    |           150 |         500 | Mon Jan 01 10:00:00 2024 |           7 | {"buckets": [{"key": "database", "doc_count": 3}, {"key": "application", "doc_count": 2}, {"key": "api", "doc_count": 1}, {"key": "network", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(7 rows)

-- Test 31: pdb.agg() window function with different ORDER BY
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER () AS avg_response
FROM logs
WHERE description @@@ 'error'
ORDER BY response_time DESC LIMIT 5;
                                                                                                                                              QUERY PLAN                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"avg":{"field":"response_time"}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: response_time desc
            TopN Limit: 5
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
(11 rows)

SELECT *,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) OVER () AS avg_response
FROM logs
WHERE description @@@ 'error'
ORDER BY response_time DESC LIMIT 5;
 id |        description         | severity | category | response_time | status_code |        timestamp         |         avg_response         
----+----------------------------+----------+----------+---------------+-------------+--------------------------+------------------------------
 15 | Network timeout error      | critical | network  |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"value": 2101.714285714286}
  3 | Database timeout error     | critical | database |          3000 |         503 | Mon Jan 01 10:05:00 2024 | {"value": 2101.714285714286}
 11 | API internal server error  | critical | api      |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"value": 2101.714285714286}
  1 | Database connection error  | error    | database |           150 |         500 | Mon Jan 01 10:00:00 2024 | {"value": 2101.714285714286}
  2 | Invalid query syntax error | error    | database |            50 |         400 | Mon Jan 01 10:03:00 2024 | {"value": 2101.714285714286}
(5 rows)

-- =====================================================================
-- SECTION 8: pdb.agg() with ORDER BY
-- =====================================================================
-- Test 32: pdb.agg() with ORDER BY on GROUP BY column
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category DESC;
                                                                                          QUERY PLAN                                                                                          
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","order":{"_key":"desc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category DESC;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 33: pdb.agg() with multiple ORDER BY columns
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, severity, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category, severity
ORDER BY category ASC, severity DESC;
                                                                                                                                               QUERY PLAN                                                                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, severity, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category, severity
     Aggregate Definition: {"grouped":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"severity","order":{"_key":"desc"},"segment_size":65000,"size":65000}}},"terms":{"field":"category","order":{"_key":"asc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, severity, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category, severity
ORDER BY category ASC, severity DESC;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- =====================================================================
-- SECTION 9: pdb.agg() with FILTER (GROUP BY context)
-- =====================================================================
-- Test 34: pdb.agg() with FILTER on indexed field (GROUP BY)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE severity @@@ 'error')
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                                                                                                                                                                                                                                                    QUERY PLAN                                                                                                                                                                                                                                                                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"0":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"with_index":{"query":{"parse_with_field":{"conjunction_mode":null,"field":"severity","lenient":null,"query_string":"error"}}}}},"filter_sentinel":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"with_index":{"query":{"parse_with_field":{"conjunction_mode":null,"field":"description","lenient":null,"query_string":"error"}}}}}}
(7 rows)

SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE severity @@@ 'error')
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 35: pdb.agg() with FILTER on numeric field (GROUP BY)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) FILTER (WHERE status_code >= 500)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                                                                                                                                                                                                                     QUERY PLAN                                                                                                                                                                                                                                                                                      
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"severity"}})
     Group By: category
     Aggregate Definition: {"0":{"aggs":{"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"range":{"field":"status_code","is_datetime":false,"lower_bound":{"included":500},"upper_bound":null}}},"filter_sentinel":{"aggs":{"grouped":{"aggs":{"0":{"terms":{"field":"severity"}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"with_index":{"query":{"parse_with_field":{"conjunction_mode":null,"field":"description","lenient":null,"query_string":"error"}}}}}}
(7 rows)

SELECT category,
       pdb.agg('{"terms": {"field": "severity"}}'::jsonb) FILTER (WHERE status_code >= 500)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
  category   |                                                                       agg                                                                        
-------------+--------------------------------------------------------------------------------------------------------------------------------------------------
 database    | {"buckets": [{"key": "error", "doc_count": 1}, {"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 application | {"buckets": [{"key": "critical", "doc_count": 2}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 api         | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
 network     | {"buckets": [{"key": "critical", "doc_count": 1}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(4 rows)

-- Test 36: Multiple pdb.agg() with different FILTER clauses
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE status_code >= 500) AS avg_5xx,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE status_code < 500) AS avg_4xx
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
                                                                                                                                                                                                                                                                                                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}}), CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"0":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"range":{"field":"status_code","is_datetime":false,"lower_bound":{"included":500},"upper_bound":null}}},"1":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"range":{"field":"status_code","is_datetime":false,"lower_bound":null,"upper_bound":{"excluded":500}}}},"filter_sentinel":{"aggs":{"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}},"1":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","segment_size":65000,"size":65000}}},"filter":{"with_index":{"query":{"parse_with_field":{"conjunction_mode":null,"field":"description","lenient":null,"query_string":"error"}}}}}}
(7 rows)

SELECT category,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE status_code >= 500) AS avg_5xx,
       pdb.agg('{"avg": {"field": "response_time"}}'::jsonb) FILTER (WHERE status_code < 500) AS avg_4xx
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- =====================================================================
-- SECTION 10: pdb.agg() Edge Cases
-- =====================================================================
-- Test 37: pdb.agg() with contradictory WHERE clauses
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error') AND (NOT (description @@@ 'error'));
                                                                                                                                                                        QUERY PLAN                                                                                                                                                                         
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"boolean":{"must":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}]}}]}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"category"}})
     Aggregate Definition: {"0":{"terms":{"field":"category"}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error') AND (NOT (description @@@ 'error'));
 agg 
-----
 
(1 row)

-- Test 38: pdb.agg() with tautological WHERE clause
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error') OR (NOT (description @@@ 'error'));
                                                                                                                                                                         QUERY PLAN                                                                                                                                                                          
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"boolean":{"should":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}]}}]}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Aggregate Definition: {"0":{"avg":{"field":"response_time","missing":null}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE (description @@@ 'error') OR (NOT (description @@@ 'error'));
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- Test 39: pdb.agg() with all() query
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE id @@@ paradedb.all();
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":"all"}}
     Applies to Aggregates: CUSTOM_AGG({"terms":{"field":"category"}})
     Aggregate Definition: {"0":{"terms":{"field":"category"}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE id @@@ paradedb.all();
                                                                                                                               agg                                                                                                                               
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"key": "database", "doc_count": 6}, {"key": "api", "doc_count": 5}, {"key": "application", "doc_count": 4}, {"key": "network", "doc_count": 4}, {"key": "security", "doc_count": 3}], "sum_other_doc_count": 0, "doc_count_error_upper_bound": 0}
(1 row)

-- Test 40: pdb.agg() with GROUP BY and all() query
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE id @@@ paradedb.all()
GROUP BY category
ORDER BY category;
                                                                                         QUERY PLAN                                                                                          
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":"all"}}
     Applies to Aggregates: CUSTOM_AGG({"avg":{"field":"response_time"}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"avg":{"field":"response_time","missing":null}}},"terms":{"field":"category","order":{"_key":"asc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, pdb.agg('{"avg": {"field": "response_time"}}'::jsonb)
FROM logs
WHERE id @@@ paradedb.all()
GROUP BY category
ORDER BY category;
ERROR:  called `Result::unwrap()` on an `Err` value: UnsupportedIntoConversion("jsonb")
-- =====================================================================
-- SECTION 11: Range Histogram (Classic Faceting Pattern)
-- =====================================================================
-- Test 41: Range histogram for response time buckets
-- This is a common faceting pattern - much more efficient than using CASE/CTE
-- Equivalent to: CASE WHEN response_time < 100 THEN '0-100' WHEN ... END
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"range": {"field": "response_time", "ranges": [
    {"to": 100, "key": "fast"},
    {"from": 100, "to": 1000, "key": "medium"},
    {"from": 1000, "key": "slow"}
]}}'::jsonb) AS response_time_buckets
FROM logs
WHERE description @@@ 'error';
                                                                                                                         QUERY PLAN                                                                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"range":{"field":"response_time","ranges":[{"to":100,"key":"fast"},{"to":1000,"key":"medium","from":100},{"key":"slow","from":1000}]}})
     Aggregate Definition: {"0":{"range":{"field":"response_time","keyed":false,"ranges":[{"key":"fast","to":100.0},{"from":100.0,"key":"medium","to":1000.0},{"from":1000.0,"key":"slow"}]}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"range": {"field": "response_time", "ranges": [
    {"to": 100, "key": "fast"},
    {"from": 100, "to": 1000, "key": "medium"},
    {"from": 1000, "key": "slow"}
]}}'::jsonb) AS response_time_buckets
FROM logs
WHERE description @@@ 'error';
                                                                            response_time_buckets                                                                             
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
(1 row)

-- Test 42: Range histogram with GROUP BY
-- Facet response time buckets per category
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT category, 
       pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) AS response_time_buckets
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category;
                                                                                                                                                QUERY PLAN                                                                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: category, pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"range":{"field":"response_time","ranges":[{"to":100,"key":"fast"},{"to":1000,"key":"medium","from":100},{"key":"slow","from":1000}]}})
     Group By: category
     Aggregate Definition: {"grouped":{"aggs":{"0":{"range":{"field":"response_time","keyed":false,"ranges":[{"key":"fast","to":100.0},{"from":100.0,"key":"medium","to":1000.0},{"from":1000.0,"key":"slow"}]}}},"terms":{"field":"category","order":{"_key":"asc"},"segment_size":65000,"size":65000}}}
(7 rows)

SELECT category, 
       pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) AS response_time_buckets
FROM logs
WHERE description @@@ 'error'
GROUP BY category
ORDER BY category;
  category   |                                                                            response_time_buckets                                                                             
-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 api         | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 0}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 0}, {"key": "slow", "from": 1000.0, "doc_count": 1}]}
 application | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 2}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 0}, {"key": "slow", "from": 1000.0, "doc_count": 0}]}
 database    | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 1}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 1}]}
 network     | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 0}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 0}, {"key": "slow", "from": 1000.0, "doc_count": 1}]}
(4 rows)

-- Test 43: Range histogram for status codes (HTTP status buckets)
-- Common pattern: 2xx, 3xx, 4xx, 5xx buckets
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"range": {"field": "status_code", "ranges": [
    {"from": 200, "to": 300, "key": "2xx"},
    {"from": 300, "to": 400, "key": "3xx"},
    {"from": 400, "to": 500, "key": "4xx"},
    {"from": 500, "to": 600, "key": "5xx"}
]}}'::jsonb) AS status_code_buckets
FROM logs
WHERE id @@@ paradedb.all();
                                                                                                                                                   QUERY PLAN                                                                                                                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":"all"}}
     Applies to Aggregates: CUSTOM_AGG({"range":{"field":"status_code","ranges":[{"to":300,"key":"2xx","from":200},{"to":400,"key":"3xx","from":300},{"to":500,"key":"4xx","from":400},{"to":600,"key":"5xx","from":500}]}})
     Aggregate Definition: {"0":{"range":{"field":"status_code","keyed":false,"ranges":[{"from":200.0,"key":"2xx","to":300.0},{"from":300.0,"key":"3xx","to":400.0},{"from":400.0,"key":"4xx","to":500.0},{"from":500.0,"key":"5xx","to":600.0}]}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"range": {"field": "status_code", "ranges": [
    {"from": 200, "to": 300, "key": "2xx"},
    {"from": 300, "to": 400, "key": "3xx"},
    {"from": 400, "to": 500, "key": "4xx"},
    {"from": 500, "to": 600, "key": "5xx"}
]}}'::jsonb) AS status_code_buckets
FROM logs
WHERE id @@@ paradedb.all();
                                                                                                                                                                      status_code_buckets                                                                                                                                                                       
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"to": 200.0, "key": "*-200", "doc_count": 0}, {"to": 300.0, "key": "2xx", "from": 200.0, "doc_count": 1}, {"to": 400.0, "key": "3xx", "from": 300.0, "doc_count": 0}, {"to": 500.0, "key": "4xx", "from": 400.0, "doc_count": 8}, {"to": 600.0, "key": "5xx", "from": 500.0, "doc_count": 13}, {"key": "600-*", "from": 600.0, "doc_count": 0}]}
(1 row)

-- Test 44: Multiple range histograms in one query
-- Get both response time and status code distributions
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) AS response_time_buckets,
       pdb.agg('{"range": {"field": "status_code", "ranges": [
           {"from": 400, "to": 500, "key": "4xx"},
           {"from": 500, "to": 600, "key": "5xx"}
       ]}}'::jsonb) AS status_code_buckets
FROM logs
WHERE description @@@ 'error';
                                                                                                                                                                                              QUERY PLAN                                                                                                                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (ParadeDB Aggregate Scan) on public.logs
   Output: pdb.agg_fn('pdb.AGG'::text), pdb.agg_fn('pdb.AGG'::text)
   Index: logs_idx
   Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
     Applies to Aggregates: CUSTOM_AGG({"range":{"field":"response_time","ranges":[{"to":100,"key":"fast"},{"to":1000,"key":"medium","from":100},{"key":"slow","from":1000}]}}), CUSTOM_AGG({"range":{"field":"status_code","ranges":[{"to":500,"key":"4xx","from":400},{"to":600,"key":"5xx","from":500}]}})
     Aggregate Definition: {"0":{"range":{"field":"response_time","keyed":false,"ranges":[{"key":"fast","to":100.0},{"from":100.0,"key":"medium","to":1000.0},{"from":1000.0,"key":"slow"}]}},"1":{"range":{"field":"status_code","keyed":false,"ranges":[{"from":400.0,"key":"4xx","to":500.0},{"from":500.0,"key":"5xx","to":600.0}]}},"_doc_count":{"value_count":{"field":"ctid","missing":null}}}
(6 rows)

SELECT pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) AS response_time_buckets,
       pdb.agg('{"range": {"field": "status_code", "ranges": [
           {"from": 400, "to": 500, "key": "4xx"},
           {"from": 500, "to": 600, "key": "5xx"}
       ]}}'::jsonb) AS status_code_buckets
FROM logs
WHERE description @@@ 'error';
                                                                            response_time_buckets                                                                             |                                                                                                          status_code_buckets                                                                                                          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]} | {"buckets": [{"to": 400.0, "key": "*-400", "doc_count": 0}, {"to": 500.0, "key": "4xx", "from": 400.0, "doc_count": 1}, {"to": 600.0, "key": "5xx", "from": 500.0, "doc_count": 6}, {"key": "600-*", "from": 600.0, "doc_count": 0}]}
(1 row)

-- Test 45: Range histogram with TopN (window function)
-- Get response time distribution alongside top N results
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF, VERBOSE)
SELECT *,
       pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) OVER () AS response_time_distribution
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
                                                                                                                                                                                                 QUERY PLAN                                                                                                                                                                                                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: id, description, severity, category, response_time, status_code, "timestamp", (pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"range":{"field":"response_time","ranges":[{"to":100,"key":"fast"},{"to":1000,"key":"medium","from":100},{"key":"slow","from":1000}]}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text))
   ->  Custom Scan (ParadeDB Scan) on public.logs
         Output: id, description, severity, category, response_time, status_code, "timestamp", pdb.window_agg('{"entries":[{"Aggregate":{"Custom":{"agg_json":{"range":{"field":"response_time","ranges":[{"to":100,"key":"fast"},{"to":1000,"key":"medium","from":100},{"key":"slow","from":1000}]}},"filter":null,"indexrelid":0}}}],"groupby":{"grouping_columns":[]},"uses_our_operator":false}'::text)
         Table: logs
         Index: logs_idx
         Exec Method: TopNScanExecState
         Scores: false
            TopN Order By: timestamp desc
            TopN Limit: 10
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"error","lenient":null,"conjunction_mode":null}}}}
(11 rows)

SELECT *,
       pdb.agg('{"range": {"field": "response_time", "ranges": [
           {"to": 100, "key": "fast"},
           {"from": 100, "to": 1000, "key": "medium"},
           {"from": 1000, "key": "slow"}
       ]}}'::jsonb) OVER () AS response_time_distribution
FROM logs
WHERE description @@@ 'error'
ORDER BY timestamp DESC LIMIT 10;
 id |        description         | severity |  category   | response_time | status_code |        timestamp         |                                                                          response_time_distribution                                                                          
----+----------------------------+----------+-------------+---------------+-------------+--------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 11 | API internal server error  | critical | api         |          1500 |         500 | Mon Jan 01 10:21:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
 19 | Stack overflow error       | critical | application |             2 |         500 | Mon Jan 01 10:18:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
 15 | Network timeout error      | critical | network     |         10000 |         504 | Mon Jan 01 10:17:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
 17 | Memory allocation error    | critical | application |            10 |         500 | Mon Jan 01 10:08:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
  3 | Database timeout error     | critical | database    |          3000 |         503 | Mon Jan 01 10:05:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
  2 | Invalid query syntax error | error    | database    |            50 |         400 | Mon Jan 01 10:03:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
  1 | Database connection error  | error    | database    |           150 |         500 | Mon Jan 01 10:00:00 2024 | {"buckets": [{"to": 100.0, "key": "fast", "doc_count": 3}, {"to": 1000.0, "key": "medium", "from": 100.0, "doc_count": 1}, {"key": "slow", "from": 1000.0, "doc_count": 3}]}
(7 rows)

-- =====================================================================
-- SECTION 12: Error Handling - Aggregate Custom Scan Disabled
-- =====================================================================
-- Test 46: pdb.agg() with aggregate custom scan disabled (should error)
SET paradedb.enable_aggregate_custom_scan TO off;
SELECT pdb.agg('{"terms": {"field": "category"}}'::jsonb)
FROM logs
WHERE description @@@ 'error';
ERROR:  pdb.agg() requires aggregate custom scan to be enabled. Set 'paradedb.enable_aggregate_custom_scan = on' to use pdb.agg().
-- Test 47: pdb.agg() with GROUP BY and aggregate custom scan disabled (should error)
SELECT category, pdb.agg('{"terms": {"field": "severity"}}'::jsonb)
FROM logs
WHERE description @@@ 'error'
GROUP BY category;
ERROR:  pdb.agg() requires aggregate custom scan to be enabled. Set 'paradedb.enable_aggregate_custom_scan = on' to use pdb.agg().
-- Re-enable for cleanup
SET paradedb.enable_aggregate_custom_scan TO on;
-- Cleanup
DROP TABLE logs CASCADE;
