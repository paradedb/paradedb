\i common/common_setup.sql
CREATE EXTENSION IF NOT EXISTS pg_search;
-- Disable parallel workers to avoid differences in plans
SET max_parallel_workers_per_gather = 0;
SET enable_indexscan to OFF;
SET paradedb.enable_mixed_fast_field_exec = true;
-- Test index-level search_tokenizer as a WITH option.
--
-- The search_tokenizer WITH option sets a default search-time tokenizer
-- for all text/JSON fields in the index.
-------------------------------------------------------------
-- Test 1: Basic index-level search_tokenizer
-------------------------------------------------------------
DROP TABLE IF EXISTS autocomplete;
CREATE TABLE autocomplete (
    id serial8 NOT NULL PRIMARY KEY,
    title text
);
INSERT INTO autocomplete (title) VALUES
    ('shoes'), ('shirt'), ('shorts'), ('shoelaces'), ('socks');
CREATE INDEX idx_autocomplete ON autocomplete USING bm25
    (id, (title::pdb.ngram(1, 10, 'prefix_only=true')))
    WITH (key_field = 'id', search_tokenizer = 'unicode_words');
-- "sho" stays as one token at search time -> matches titles with prefix "sho"
EXPLAIN (COSTS OFF, VERBOSE, TIMING OFF)
SELECT id, title FROM autocomplete WHERE title ||| 'sho' ORDER BY id;
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Output: id, title
   Sort Key: autocomplete.id
   ->  Custom Scan (ParadeDB Scan) on public.autocomplete
         Output: id, title
         Table: autocomplete
         Index: idx_autocomplete
         Exec Method: NormalScanExecState
         Scores: false
         Tantivy Query: {"with_index":{"query":{"match":{"field":"title","value":"sho","tokenizer":null,"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":false}}}}
(10 rows)

SELECT id, title FROM autocomplete WHERE title ||| 'sho' ORDER BY id;
 id |   title   
----+-----------
  1 | shoes
  3 | shorts
  4 | shoelaces
(3 rows)

-- "s" stays as one token -> matches every title starting with s
SELECT id, title FROM autocomplete WHERE title ||| 's' ORDER BY id;
 id |   title   
----+-----------
  1 | shoes
  2 | shirt
  3 | shorts
  4 | shoelaces
  5 | socks
(5 rows)

-------------------------------------------------------------
-- Test 2: Query-level tokenizer cast overrides index-level
-------------------------------------------------------------
-- On autocomplete table: force edge ngram tokenization at query time
-- "sho" gets ngrammed into s, sh, sho -> matches all 5 titles
SELECT id, title FROM autocomplete WHERE title ||| 'sho'::pdb.ngram(1, 10, 'prefix_only=true') ORDER BY id;
 id |   title   
----+-----------
  1 | shoes
  2 | shirt
  3 | shorts
  4 | shoelaces
  5 | socks
(5 rows)

-------------------------------------------------------------
-- Test 3: Parameterized expression as WITH option
-------------------------------------------------------------
DROP TABLE IF EXISTS param_test;
CREATE TABLE param_test (
    id serial8 NOT NULL PRIMARY KEY,
    content text
);
INSERT INTO param_test (content) VALUES
    ('Running Fast'), ('running slow'), ('RUNNING late');
CREATE INDEX idx_param ON param_test USING bm25
    (id, content)
    WITH (key_field = 'id', search_tokenizer = 'simple(lowercase=false)');
-- "Running" not lowered at search time -> no match against lowered index tokens -> 0 rows
SELECT id, content FROM param_test WHERE content ||| 'Running' ORDER BY id;
 id | content 
----+---------
(0 rows)

-- "running" already lowercase -> matches all 3 rows
SELECT id, content FROM param_test WHERE content ||| 'running' ORDER BY id;
 id |   content    
----+--------------
  1 | Running Fast
  2 | running slow
  3 | RUNNING late
(3 rows)

-------------------------------------------------------------
-- Test 4: search_tokenizer rejected as typmod param
-------------------------------------------------------------
-- search_tokenizer should only be set as a WITH option, not per-field
CREATE INDEX idx_bad ON autocomplete
    USING bm25 (id, (title::pdb.ngram(1, 10, 'search_tokenizer=unicode_words')))
    WITH (key_field = 'id');
ERROR:  Invalid option: 'search_tokenizer'. Allowed options: alias, alpha_num_only, ascii_folding, columnar, fieldnorms, lowercase, max, min, normalizer, positions, prefix_only, remove_long, remove_short, stemmer, stopwords, stopwords_language, trim.
-------------------------------------------------------------
-- Cleanup
-------------------------------------------------------------
DROP TABLE autocomplete;
DROP TABLE param_test;
