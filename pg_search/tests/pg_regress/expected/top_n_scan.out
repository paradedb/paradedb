-- Test file to investigate query slowdown with range fields
-- This test specifically examines why a query with LIMIT is not using TopNScanExecState
-- Setup
\i common/mixedff_advanced_setup.sql
CREATE EXTENSION IF NOT EXISTS pg_search;
-- Disable parallel workers to avoid differences in plans
SET max_parallel_workers_per_gather = 0;
SET enable_indexscan to OFF;
SET paradedb.enable_mixed_fast_field_exec = true;
-- Drop any existing test tables from this group
DROP TABLE IF EXISTS documents CASCADE;
DROP TABLE IF EXISTS files CASCADE; 
DROP TABLE IF EXISTS pages CASCADE;
DROP TABLE IF EXISTS mixed_numeric_string_test CASCADE;
DROP TABLE IF EXISTS categories CASCADE;
DROP TABLE IF EXISTS products CASCADE;
DROP TABLE IF EXISTS conversion_test CASCADE;
-- Create test table for mixed fast and non-fast fields
CREATE TABLE mixed_numeric_string_test (
    id TEXT PRIMARY KEY,
    numeric_field1 INTEGER NOT NULL,
    numeric_field2 BIGINT NOT NULL,
    string_field1 TEXT NOT NULL,
    string_field2 TEXT NOT NULL,
    string_field3 TEXT NOT NULL,
    content TEXT
);
CREATE INDEX mixed_test_search ON mixed_numeric_string_test USING bm25 (
    id,
    numeric_field1,
    numeric_field2,
    string_field1,
    string_field2,
    string_field3,
    content
) WITH (
    key_field = 'id',
    text_fields = '{"string_field1": {"tokenizer": {"type": "default"}, "fast": true}, "string_field2": {"tokenizer": {"type": "default"}, "fast": true}, "string_field3": {"tokenizer": {"type": "default"}, "fast": true}, "content": {"tokenizer": {"type": "default"}}}',
    numeric_fields = '{"numeric_field1": {"fast": true}, "numeric_field2": {"fast": true}}'
);
psql:common/mixedff_advanced_setup.sql:40: WARNING:  the `raw` tokenizer is deprecated
-- Insert test data
INSERT INTO mixed_numeric_string_test (id, numeric_field1, numeric_field2, string_field1, string_field2, string_field3, content) VALUES
('mix1', 100, 10000, 'Apple', 'Red', 'Fruit', 'This is a red apple'),
('mix2', 200, 20000, 'Banana', 'Yellow', 'Fruit', 'This is a yellow banana'),
('mix3', 300, 30000, 'Carrot', 'Orange', 'Vegetable', 'This is an orange carrot'),
('mix4', 400, 40000, 'Donut', 'Brown', 'Dessert', 'This is a chocolate donut'),
('mix5', 500, 50000, 'Egg', 'White', 'Protein', 'This is a white egg');
-- Data for window functions and UNION
DO $$
DECLARE
    i INTEGER;
BEGIN
    FOR i IN 1..10 LOOP
        INSERT INTO mixed_numeric_string_test (
            id, 
            numeric_field1, 
            numeric_field2, 
            string_field1, 
            string_field2, 
            string_field3, 
            content
        ) VALUES (
            'window' || i,
            (i * 10),
            (i * 100),
            'Group' || (i % 3),
            'Window' || (i % 2),
            'Test',
            'Window function test with searchable terms'
        );
    END LOOP;
END $$;
-- Set up document tables for advanced features
CREATE TABLE documents (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    content TEXT,
    parents TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);
CREATE TABLE files (
    id TEXT NOT NULL UNIQUE,
    documentId TEXT NOT NULL,
    title TEXT NOT NULL,
    file_path TEXT NOT NULL,
    file_size INTEGER,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (id, documentId),
    FOREIGN KEY (documentId) REFERENCES documents(id)
);
CREATE TABLE pages (
    id TEXT NOT NULL UNIQUE,
    fileId TEXT NOT NULL,
    page_number INTEGER NOT NULL,
    content TEXT NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (id, fileId),
    FOREIGN KEY (fileId) REFERENCES files(id)
);
-- Create BM25 indexes
CREATE INDEX documents_search ON documents USING bm25 (
    id,
    title,
    parents,
    content
) WITH (
    key_field = 'id',
    text_fields = '{"title": {"tokenizer": {"type": "default"}, "fast": true}, "parents": {"tokenizer": {"type": "default"}, "fast": true}, "content": {"tokenizer": {"type": "default"}, "fast": true}}'
);
psql:common/mixedff_advanced_setup.sql:116: WARNING:  the `raw` tokenizer is deprecated
CREATE INDEX files_search ON files USING bm25 (
    id,
    documentId,
    title,
    file_path
) WITH (
    key_field = 'id',
    text_fields = '{"documentid": {"tokenizer": {"type": "keyword"}, "fast": true}, "title": {"tokenizer": {"type": "default"}, "fast": true}, "file_path": {"tokenizer": {"type": "default"}, "fast": true}}'
);
psql:common/mixedff_advanced_setup.sql:126: WARNING:  the `raw` tokenizer is deprecated
CREATE INDEX pages_search ON pages USING bm25 (
    id,
    fileId,
    content,
    page_number
) WITH (
    key_field = 'id',
    text_fields = '{"fileid": {"tokenizer": {"type": "keyword"}, "fast": true}, "content": {"tokenizer": {"type": "default"}}}',
    numeric_fields = '{"page_number": {"fast": true}}'
);
psql:common/mixedff_advanced_setup.sql:137: WARNING:  the `raw` tokenizer is deprecated
-- Insert sample data
INSERT INTO documents (id, title, content, parents) VALUES
('doc1', 'Invoice 2023', 'This is an invoice for services rendered in 2023', 'Factures'),
('doc2', 'Receipt 2023', 'This is a receipt for payment received in 2023', 'Factures'),
('doc3', 'Contract 2023', 'This is a contract for services in 2023', 'Contracts');
INSERT INTO files (id, documentId, title, file_path, file_size) VALUES
('file1', 'doc1', 'Invoice PDF', '/invoices/2023.pdf', 1024),
('file2', 'doc1', 'Invoice Receipt', '/invoices/2023_receipt.pdf', 512),
('file3', 'doc2', 'Receipt', '/receipts/2023.pdf', 256),
('file4', 'doc3', 'Contract Document', '/contracts/2023.pdf', 2048);
INSERT INTO pages (id, fileId, page_number, content) VALUES
('page1', 'file1', 1, 'Page 1 of Invoice PDF with Socienty General details'),
('page2', 'file1', 2, 'Page 2 of Invoice PDF with payment information'),
('page3', 'file2', 1, 'Page 1 of Invoice Receipt with bank details'),
('page4', 'file3', 1, 'Page 1 of Receipt with Socienty General information'),
('page5', 'file3', 2, 'Page 2 of Receipt with transaction ID'),
('page6', 'file4', 1, 'Page 1 of Contract Document with terms and conditions');
-- Create recursive CTE test data
CREATE TABLE categories (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    parent_id INTEGER REFERENCES categories(id)
);
CREATE INDEX category_search ON categories USING bm25 (
    id,
    name,
    description
) WITH (
    key_field = 'id',
    text_fields = '{"name": {"tokenizer": {"type": "default"}, "fast": true}, "description": {"tokenizer": {"type": "default"}, "fast": true}}'
);
INSERT INTO categories (name, description, parent_id) VALUES
('Electronics', 'Electronic devices and accessories', NULL),
('Computers', 'Desktop and laptop computers', 1),
('Smartphones', 'Mobile phones and accessories', 1),
('Clothing', 'Apparel and fashion items', NULL),
('Men''s Clothing', 'Clothing for men', 4),
('Women''s Clothing', 'Clothing for women', 4),
('Food', 'Edible products', NULL),
('Dairy', 'Milk and dairy products', 7),
('Bakery', 'Bread and baked goods', 7);
-- Create products for multi-index search
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    category_id INTEGER REFERENCES categories(id),
    price FLOAT NOT NULL
);
CREATE INDEX product_search ON products USING bm25 (
    id,
    name,
    category_id,
    price
) WITH (
    key_field = 'id',
    text_fields = '{"name": {"tokenizer": {"type": "default"}, "fast": true}}',
    numeric_fields = '{"category_id": {"fast": true}, "price": {"fast": true}}'
);
INSERT INTO products (name, category_id, price) VALUES
('Laptop Pro', 2, 1299.99),
('Smartphone X', 3, 899.99),
('Men''s Shirt', 5, 49.99),
('Women''s Dress', 6, 199.99),
('Milk Carton', 8, 3.99),
('Bread Loaf', 9, 5.99);
-- Create table for type conversion testing
CREATE TABLE conversion_test (
    id TEXT PRIMARY KEY,
    smallint_field SMALLINT,
    integer_field INTEGER,
    bigint_field BIGINT,
    numeric_field FLOAT,
    real_field REAL,
    double_field DOUBLE PRECISION,
    bool_from_int BOOLEAN,
    timestamp_field TIMESTAMP,
    content TEXT
);
CREATE INDEX conversion_search ON conversion_test USING bm25 (
    id, 
    smallint_field, 
    integer_field, 
    bigint_field, 
    numeric_field, 
    real_field, 
    double_field, 
    bool_from_int,
    timestamp_field,
    content
) WITH (
    key_field = 'id',
    text_fields = '{"content": {"tokenizer": {"type": "default"}}}',
    numeric_fields = '{
        "smallint_field": {"fast": true}, 
        "integer_field": {"fast": true}, 
        "bigint_field": {"fast": true}, 
        "numeric_field": {"fast": true}, 
        "real_field": {"fast": true}, 
        "double_field": {"fast": true}
    }',
    boolean_fields = '{"bool_from_int": {"fast": true}}'
);
psql:common/mixedff_advanced_setup.sql:251: WARNING:  the `raw` tokenizer is deprecated
INSERT INTO conversion_test VALUES
('conv1', 32767, 2147483647, 9223372036854775807, 9999999.99, 3.402e38, 1.7976931348623157e308, true, '1988-04-29', 'conversion test'),
('conv2', -32768, -2147483648, -9223372036854775808, -9999999.99, -3.402e38, -1.7976931348623157e308, false, '1999-12-31', 'conversion test'),
('conv3', 0, 0, 0, 0.0, 0.0, 0.0, false, '2000-01-01', 'conversion test');
-- Add a product with a distinct string for testing
INSERT INTO mixed_numeric_string_test (id, numeric_field1, numeric_field2, string_field1, string_field2, string_field3, content) VALUES
('unique1', 42, 4242, 'Unique Product Z', 'Test', 'Item', 'This is a uniqueproductZ for testing mixed fields'); 
-- Create test tables
DROP TABLE IF EXISTS union_test_a;
DROP TABLE IF EXISTS union_test_b;
CREATE TABLE union_test_a (
    id SERIAL PRIMARY KEY,
    title TEXT,
    author TEXT,
    rating FLOAT,
    year INTEGER,
    price FLOAT,
    is_published BOOLEAN
);
CREATE TABLE union_test_b (
    id SERIAL PRIMARY KEY,
    title TEXT,
    author TEXT,
    rating FLOAT,
    year INTEGER,
    price FLOAT,
    is_published BOOLEAN
);
-- Insert test data with deterministic values
INSERT INTO union_test_a (title, author, rating, year, price, is_published)
SELECT
    'Book A' || i,
    'Author ' || (1 + (i % 10)),
    (3 + (i % 3))::float,  -- Ratings from 3 to 5
    2000 + (i % 22),
    (10 + (i * 5))::float,   -- Deterministic prices
    i % 3 != 0               -- Deterministic boolean pattern
FROM generate_series(1, 50) i;
INSERT INTO union_test_b (title, author, rating, year, price, is_published)
SELECT
    'Book B' || i,
    'Author ' || (1 + (i % 15)),
    (1 + (i % 5))::float,  -- Ratings from 1 to 5
    1980 + (i % 40),
    (15 + (i * 3))::float,   -- Deterministic prices
    i % 4 != 0               -- Deterministic boolean pattern
FROM generate_series(1, 50) i;
-- Create indices with mixed fast fields
DROP INDEX IF EXISTS union_test_a_idx;
DROP INDEX IF EXISTS union_test_b_idx;
CREATE INDEX union_test_a_idx ON union_test_a
USING bm25 (id, title, author, rating, year, price, is_published)
WITH (
    key_field = 'id',
    text_fields = '{"title": {"tokenizer": {"type": "default"}, "fast": true}, "author": {"tokenizer": {"type": "default"}, "fast": true}}',
    numeric_fields = '{"rating": {"fast": true}, "year": {"fast": true}, "price": {"fast": true}}',
    boolean_fields = '{"is_published": {"fast": true}}'
);
CREATE INDEX union_test_b_idx ON union_test_b
USING bm25 (id, title, author, rating, year, price, is_published)
WITH (
    key_field = 'id',
    text_fields = '{"title": {"tokenizer": {"type": "default"}, "fast": true}, "author": {"tokenizer": {"type": "default"}, "fast": true}}',
    numeric_fields = '{"rating": {"fast": true}, "year": {"fast": true}, "price": {"fast": true}}',
    boolean_fields = '{"is_published": {"fast": true}}'
);
-- Create test table with a structure containing various field types
DROP TABLE IF EXISTS records;
CREATE TABLE records (
    id SERIAL PRIMARY KEY,
    tenant_id TEXT,
    source_id TEXT,
    recipient_id TEXT,
    currency_code TEXT,
    recipient_name TEXT,
    reference_data TEXT,
    additional_info TEXT,
    flow_type TEXT,
    is_active BOOLEAN,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    routing_code TEXT,
    value_range NUMRANGE,
    time_period TSTZRANGE,
    state TEXT,
    metadata JSONB,
    notes TEXT,
    version_num INTEGER,
    process_method TEXT,
    origin_source TEXT,
    filter_config JSONB,
    system_name TEXT,
    link_count1 INTEGER,
    link_count2 INTEGER,
    amount_value NUMERIC,
    processed_amount NUMERIC,
    rule_id TEXT,
    tags TEXT[],
    external_id TEXT,
    removed_at TIMESTAMP
);
-- Insert test data
INSERT INTO records (
    tenant_id, source_id, notes, is_active,
    time_period, removed_at, currency_code, state, flow_type
)
SELECT
    'tenant-' || (i % 10),  -- 10 different tenants
    'source-' || (i % 100),  -- 100 different source IDs
    CASE WHEN i % 5 = 0 THEN 'check payment'
         WHEN i % 5 = 1 THEN 'check deposit'
         WHEN i % 5 = 2 THEN 'wire transfer'
         WHEN i % 5 = 3 THEN 'ach payment'
         ELSE 'credit card payment'
    END,
    i % 3 = 0,  -- 1/3 are is_active=true
    tstzrange(
        '2023-01-01'::timestamptz + ((i % 365) || ' days')::interval,
        '2023-01-01'::timestamptz + ((i % 365) || ' days')::interval + '1 day'::interval
    ),
    CASE WHEN i % 7 = 0 THEN '2023-06-01'::timestamp + ((i % 30) || ' days')::interval ELSE NULL END,
    CASE WHEN i % 4 = 0 THEN 'USD' WHEN i % 4 = 1 THEN 'EUR' WHEN i % 4 = 2 THEN 'GBP' ELSE 'JPY' END,
    CASE WHEN i % 3 = 0 THEN 'pending' WHEN i % 3 = 1 THEN 'completed' ELSE 'failed' END,
    CASE WHEN i % 2 = 0 THEN 'inbound' ELSE 'outbound' END
FROM generate_series(1, 10000) i;
-- Create a search index with various field types
CREATE INDEX records_search_idx ON records
USING bm25 (
    id, notes, flow_type, tenant_id, state, source_id, 
    is_active, metadata, value_range, time_period, created_at, updated_at, 
    tags, process_method, currency_code, recipient_id, 
    rule_id, link_count2, removed_at, amount_value
) WITH (
    key_field = 'id',
    text_fields = '{
        "notes": { 
            "normalizer": "lowercase", 
            "tokenizer": { "max_gram": 3, "min_gram": 3, "prefix_only": false, "type": "ngram" }
        },
        "flow_type": { "fast": true, "tokenizer": {"type": "keyword"} },
        "tenant_id": { "tokenizer": {"type": "keyword"} },
        "recipient_id": { "tokenizer": {"type": "keyword"} },
        "source_id": { "tokenizer": {"type": "keyword"} },
        "rule_id": { "tokenizer": {"type": "keyword"} },
        "tags": { "fast": true, "tokenizer": {"type": "keyword"} },
        "state": { "fast": true, "tokenizer": {"type": "keyword"} },
        "currency_code": { "tokenizer": {"type": "keyword"} },
        "process_method": { "fast": true, "tokenizer": {"type": "keyword"} }
    }',
    numeric_fields = '{"link_count2":{}, "amount_value":{}}',
    boolean_fields = '{"is_active":{}}',
    json_fields = '{ 
        "metadata": { "fast": true, "normalizer": "lowercase", "tokenizer": { "type": "raw" } }, 
        "metadata_words": { "fast": true, "normalizer": "lowercase", "tokenizer": { "type": "default" }, "column": "metadata" } 
    }',
    range_fields = '{"value_range":{"fast":true},"time_period":{"fast":true}}',
    datetime_fields = '{"created_at":{}, "removed_at":{}, "updated_at":{}}'
);
WARNING:  the `raw` tokenizer is deprecated
\echo '======== EXECUTION METHOD TESTS ========'
======== EXECUTION METHOD TESTS ========
\echo 'Tests to identify when TopNScanExecState vs NormalScanExecState is used'
Tests to identify when TopNScanExecState vs NormalScanExecState is used
-- Test 1: Simple query with LIMIT (should use TopNScanExecState)
\echo 'Test 1: Simple query with LIMIT (should use TopNScanExecState)'
Test 1: Simple query with LIMIT (should use TopNScanExecState)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, notes, tenant_id
FROM records
WHERE notes @@@ 'check'
ORDER BY id
LIMIT 25;
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: id
            Sort Direction: asc
            Top N Limit: 25
         Tantivy Query: {"with_index":{"query":{"parse_with_field":{"field":"notes","query_string":"check","lenient":null,"conjunction_mode":null}}}}
(10 rows)

-- Test 2: Query with complex conditions
\echo 'Test 2: Complex query with multiple conditions (reproducing issue)'
Test 2: Complex query with multiple conditions (reproducing issue)
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, tenant_id, source_id, notes, is_active, time_period
FROM records
WHERE tenant_id = 'tenant-1'
  AND is_active = TRUE
  AND NOT (source_id @@@ 'IN [source-1 source-2 source-3]')
  AND (id @@@ paradedb.match('notes', 'check', conjunction_mode => true, 
       tokenizer => paradedb.tokenizer('ngram', min_gram => 3, max_gram => 3, prefix_only => false)))
  AND (NOT id @@@ paradedb.exists('removed_at'))
  AND (id @@@ paradedb.all())
ORDER BY time_period DESC
LIMIT 25;
                                                                                                                                                                                                                                                                                                                                                                                              QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: time_period
            Sort Direction: desc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":[{"term":{"field":"is_active","value":true,"is_datetime":false}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"source_id","query_string":"IN [source-1 source-2 source-3]","lenient":null,"conjunction_mode":null}}}}]}},{"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":{"type":"ngram","max_gram":3,"min_gram":3,"lowercase":true,"prefix_only":false,"remove_long":255},"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":true}}}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"exists":{"field":"removed_at"}}}}]}},{"with_index":{"query":"all"}},{"term":{"field":"tenant_id","value":"tenant-1","is_datetime":false}}]}}
(10 rows)

-- Test 3: Same query without paradedb.all() operator
\echo 'Test 3: Without paradedb.all() operator'
Test 3: Without paradedb.all() operator
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, tenant_id, source_id, notes, is_active, time_period
FROM records
WHERE tenant_id = 'tenant-1'
  AND is_active = TRUE
  AND NOT (source_id @@@ 'IN [source-1 source-2 source-3]')
  AND (id @@@ paradedb.match('notes', 'check', conjunction_mode => true, 
       tokenizer => paradedb.tokenizer('ngram', min_gram => 3, max_gram => 3, prefix_only => false)))
  AND (NOT id @@@ paradedb.exists('removed_at'))
ORDER BY time_period DESC
LIMIT 25;
                                                                                                                                                                                                                                                                                                                                                                              QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                               
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: time_period
            Sort Direction: desc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":[{"term":{"field":"is_active","value":true,"is_datetime":false}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"source_id","query_string":"IN [source-1 source-2 source-3]","lenient":null,"conjunction_mode":null}}}}]}},{"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":{"type":"ngram","max_gram":3,"min_gram":3,"lowercase":true,"prefix_only":false,"remove_long":255},"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":true}}}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"exists":{"field":"removed_at"}}}}]}},{"term":{"field":"tenant_id","value":"tenant-1","is_datetime":false}}]}}
(10 rows)

-- Test 4: Testing the impact of paradedb.all() alone
\echo 'Test 4: Testing paradedb.all() by itself'
Test 4: Testing paradedb.all() by itself
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, notes
FROM records
WHERE id @@@ paradedb.all()
ORDER BY id
LIMIT 25;
                      QUERY PLAN                       
-------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: id
            Sort Direction: asc
            Top N Limit: 25
         Tantivy Query: {"with_index":{"query":"all"}}
(10 rows)

-- Test 5: Testing NOT with paradedb.exists
\echo 'Test 5: Testing NOT with paradedb.exists'
Test 5: Testing NOT with paradedb.exists
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, notes
FROM records
WHERE NOT id @@@ paradedb.exists('removed_at')
ORDER BY id
LIMIT 25;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: id
            Sort Direction: asc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"exists":{"field":"removed_at"}}}}]}}
(10 rows)

-- Test 6: Testing IN negation with @@@
\echo 'Test 6: Testing IN negation with @@@'
Test 6: Testing IN negation with @@@
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, notes
FROM records
WHERE NOT source_id @@@ 'IN [source-1 source-2 source-3]'
ORDER BY id
LIMIT 25;
                                                                                                          QUERY PLAN                                                                                                          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: id
            Sort Direction: asc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"source_id","query_string":"IN [source-1 source-2 source-3]","lenient":null,"conjunction_mode":null}}}}]}}
(10 rows)

-- Test 7: Testing simplified complex query - removing one component at a time
\echo 'Test 7: Simplified complex query - only basic conditions'
Test 7: Simplified complex query - only basic conditions
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, tenant_id, notes
FROM records
WHERE tenant_id = 'tenant-1'
  AND is_active = TRUE
  AND id @@@ paradedb.match('notes', 'check')
ORDER BY time_period DESC
LIMIT 25;
                                                                                                                                                                          QUERY PLAN                                                                                                                                                                           
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: time_period
            Sort Direction: desc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":[{"term":{"field":"is_active","value":true,"is_datetime":false}},{"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":null,"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":null}}}},{"term":{"field":"tenant_id","value":"tenant-1","is_datetime":false}}]}}
(10 rows)

-- Test 8: Testing with each complex component isolated
\echo 'Test 8: Component isolation - paradedb.match'
Test 8: Component isolation - paradedb.match
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, notes
FROM records
WHERE id @@@ paradedb.match('notes', 'check', conjunction_mode => true, 
       tokenizer => paradedb.tokenizer('ngram', min_gram => 3, max_gram => 3, prefix_only => false))
LIMIT 25;
                                                                                                                                          QUERY PLAN                                                                                                                                           
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Top N Limit: 25
         Tantivy Query: {"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":{"type":"ngram","max_gram":3,"min_gram":3,"lowercase":true,"prefix_only":false,"remove_long":255},"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":true}}}}
(8 rows)

-- Test 9: Query with all columns
\echo 'Test 9: Full query with all 31 columns'
Test 9: Full query with all 31 columns
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, tenant_id, source_id, recipient_id, currency_code, 
       recipient_name, reference_data, additional_info, flow_type,
       is_active, created_at, updated_at, routing_code, 
       value_range, time_period, state, metadata, notes, version_num,
       process_method, origin_source, filter_config, 
       system_name, link_count1, link_count2,
       amount_value, processed_amount, rule_id,
       tags, external_id, removed_at
FROM records
WHERE tenant_id = 'tenant-1'
  AND is_active = TRUE
  AND NOT (source_id @@@ 'IN [source-1 source-2 source-3]')
  AND (id @@@ paradedb.match('notes', 'check', conjunction_mode => true, 
       tokenizer => paradedb.tokenizer('ngram', min_gram => 3, max_gram => 3, prefix_only => false)))
  AND (NOT id @@@ paradedb.exists('removed_at'))
  AND (id @@@ paradedb.all())
ORDER BY time_period DESC
LIMIT 25;
                                                                                                                                                                                                                                                                                                                                                                                              QUERY PLAN                                                                                                                                                                                                                                                                                                                                                                                              
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: time_period
            Sort Direction: desc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":[{"term":{"field":"is_active","value":true,"is_datetime":false}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"parse_with_field":{"field":"source_id","query_string":"IN [source-1 source-2 source-3]","lenient":null,"conjunction_mode":null}}}}]}},{"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":{"type":"ngram","max_gram":3,"min_gram":3,"lowercase":true,"prefix_only":false,"remove_long":255},"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":true}}}},{"boolean":{"must":["all"],"must_not":[{"with_index":{"query":{"exists":{"field":"removed_at"}}}}]}},{"with_index":{"query":"all"}},{"term":{"field":"tenant_id","value":"tenant-1","is_datetime":false}}]}}
(10 rows)

-- Test 10: Fast-field only solution - selecting only indexed fast fields
\echo 'Test 10: Possible solution - selecting only fast fields'
Test 10: Possible solution - selecting only fast fields
EXPLAIN (FORMAT TEXT, COSTS OFF, TIMING OFF)
SELECT id, flow_type, state, tags, process_method
FROM records
WHERE tenant_id = 'tenant-1'
  AND is_active = TRUE
  AND (id @@@ paradedb.match('notes', 'check'))
ORDER BY time_period DESC
LIMIT 25;
                                                                                                                                                                          QUERY PLAN                                                                                                                                                                           
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   ->  Custom Scan (ParadeDB Scan) on records
         Table: records
         Index: records_search_idx
         Exec Method: TopNScanExecState
         Scores: false
            Sort Field: time_period
            Sort Direction: desc
            Top N Limit: 25
         Tantivy Query: {"boolean":{"must":[{"term":{"field":"is_active","value":true,"is_datetime":false}},{"with_index":{"query":{"match":{"field":"notes","value":"check","tokenizer":null,"distance":null,"transposition_cost_one":null,"prefix":null,"conjunction_mode":null}}}},{"term":{"field":"tenant_id","value":"tenant-1","is_datetime":false}}]}}
(10 rows)

-- Cleanup
DROP INDEX IF EXISTS records_search_idx;
DROP TABLE IF EXISTS records;
\i common/mixedff_advanced_cleanup.sql 
-- Cleanup for advanced features tests (13-21)
-- Drop the tables used in these tests (in reverse order to handle dependencies)
DROP TABLE IF EXISTS conversion_test CASCADE;
DROP TABLE IF EXISTS products CASCADE;
DROP TABLE IF EXISTS categories CASCADE;
DROP TABLE IF EXISTS pages CASCADE;
DROP TABLE IF EXISTS files CASCADE;
DROP TABLE IF EXISTS documents CASCADE;
DROP TABLE IF EXISTS mixed_numeric_string_test CASCADE;
DROP INDEX IF EXISTS union_test_a_idx CASCADE;
DROP INDEX IF EXISTS union_test_b_idx CASCADE;
DROP TABLE IF EXISTS union_test_a CASCADE;
DROP TABLE IF EXISTS union_test_b CASCADE; 
-- Reset parallel workers setting to default
RESET max_parallel_workers_per_gather;
RESET enable_indexscan;
RESET paradedb.enable_mixed_fast_field_exec;
SELECT 'Advanced features tests cleanup complete' AS status; 
                  status                  
------------------------------------------
 Advanced features tests cleanup complete
(1 row)

